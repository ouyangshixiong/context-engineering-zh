# ğŸ› ä»£ç éªŒè¯æ£€æŸ¥æ¸…å•

> ç³»ç»ŸåŒ–çš„ä»£ç éªŒè¯æµç¨‹ï¼Œç¡®ä¿ç”Ÿæˆä»£ç çš„æ­£ç¡®æ€§å’Œå¯ç”¨æ€§

## ğŸ¯ éªŒè¯æµç¨‹å›¾

```mermaid
flowchart TD
    A[å¼€å§‹è°ƒè¯•] --> B[ç¯å¢ƒæ£€æŸ¥]
    B --> C[å¯¼å…¥æµ‹è¯•]
    C --> D[æ•°æ®é›†éªŒè¯]
    D --> E[æ¨¡å‹éªŒè¯]
    E --> F[è®­ç»ƒæµ‹è¯•]
    F --> G[ç»“æœéªŒè¯]
    G --> H{å…¨éƒ¨é€šè¿‡?}
    H -->|å¦| I[é—®é¢˜ä¿®å¤]
    I --> B
    H -->|æ˜¯| J[è°ƒè¯•å®Œæˆ]
    
    style B fill:#90EE90,stroke:#333
    style F fill:#FFB6C1,stroke:#333
    style J fill:#90EE90,stroke:#333
```

## ğŸ” é˜¶æ®µ1: ç¯å¢ƒæ£€æŸ¥

### 1.1 Pythonç¯å¢ƒéªŒè¯
```bash
# æ£€æŸ¥Pythonç‰ˆæœ¬
python --version  # æœŸæœ›: 3.9-3.10

# æ£€æŸ¥ä¾èµ–ç‰ˆæœ¬
python -c "
import torch, paddle, pytorch_lightning
print(f'PyTorch: {torch.__version__}')
print(f'PaddlePaddle: {paddle.__version__}')
print(f'PyTorch Lightning: {pytorch_lightning.__version__}')
"
```

### 1.2 é¡¹ç›®è·¯å¾„æ£€æŸ¥
```bash
# æ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•
pwd  # åº”è¯¥åœ¨é¡¹ç›®æ ¹ç›®å½•

# æ£€æŸ¥PYTHONPATH
python -c "import sys; print('PYTHONPATH:', sys.path)"

# è®¾ç½®é¡¹ç›®è·¯å¾„
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
```

### 1.3 æ–‡ä»¶ç»“æ„æ£€æŸ¥
```bash
# æ£€æŸ¥å¿…éœ€æ–‡ä»¶
required_files=(
    "src/__init__.py"
    "src/models/__init__.py"
    "src/datasets/__init__.py"
    "scripts/train.py"
    "scripts/eval.py"
    "configs/config.yaml"
)

for file in "${required_files[@]}"; do
    if [ -f "$file" ]; then
        echo "âœ… $file"
    else
        echo "âŒ $file ç¼ºå¤±"
    fi
done
```

## ğŸ” é˜¶æ®µ2: å¯¼å…¥æµ‹è¯•

### 2.1 åŸºç¡€æ¨¡å—å¯¼å…¥
```bash
# æµ‹è¯•æ ¸å¿ƒæ¨¡å—å¯¼å…¥
python -c "
try:
    import src.models
    print('âœ… modelsæ¨¡å—å¯¼å…¥æˆåŠŸ')
except ImportError as e:
    print(f'âŒ modelsæ¨¡å—å¯¼å…¥å¤±è´¥: {e}')

try:
    import src.datasets
    print('âœ… datasetsæ¨¡å—å¯¼å…¥æˆåŠŸ')
except ImportError as e:
    print(f'âŒ datasetsæ¨¡å—å¯¼å…¥å¤±è´¥: {e}')
"
```

### 2.2 å…·ä½“ç±»å¯¼å…¥æµ‹è¯•
```bash
# æµ‹è¯•æ¨¡å‹ç±»å¯¼å…¥
python -c "
try:
    from src.models.pytorch.yolov10 import YOLOv10
    print('âœ… PyTorch YOLOv10æ¨¡å‹å¯¼å…¥æˆåŠŸ')
except ImportError as e:
    print(f'âŒ PyTorch YOLOv10æ¨¡å‹å¯¼å…¥å¤±è´¥: {e}')

try:
    from src.models.paddle.yolov10 import YOLOv10
    print('âœ… PaddlePaddle YOLOv10æ¨¡å‹å¯¼å…¥æˆåŠŸ')
except ImportError as e:
    print(f'âŒ PaddlePaddle YOLOv10æ¨¡å‹å¯¼å…¥å¤±è´¥: {e}')
"
```

### 2.3 æ•°æ®é›†å¯¼å…¥æµ‹è¯•
```bash
# æµ‹è¯•æ•°æ®é›†å¯¼å…¥
python -c "
try:
    from src.datasets.coco_detection import COCODetection
    print('âœ… COCOæ•°æ®é›†å¯¼å…¥æˆåŠŸ')
except ImportError as e:
    print(f'âŒ COCOæ•°æ®é›†å¯¼å…¥å¤±è´¥: {e}')

try:
    from src.datasets.datamodules.coco_datamodule import COCODataModule
    print('âœ… COCOæ•°æ®æ¨¡å—å¯¼å…¥æˆåŠŸ')
except ImportError as e:
    print(f'âŒ COCOæ•°æ®æ¨¡å—å¯¼å…¥å¤±è´¥: {e}')
"
```

## ğŸ” é˜¶æ®µ3: æ•°æ®é›†éªŒè¯

### 3.1 æ•°æ®é›†ä¸‹è½½éªŒè¯
```bash
# ä¸‹è½½æµ‹è¯•æ•°æ®é›†
python scripts/download.py --dataset coco128 --data_dir ./test_data

# éªŒè¯æ•°æ®é›†å®Œæ•´æ€§
python -c "
import os
from pathlib import Path

# æ£€æŸ¥æ•°æ®é›†ç›®å½•
data_dir = Path('./test_data/coco128')
required_dirs = ['train2017', 'val2017', 'annotations']

for dir_name in required_dirs:
    dir_path = data_dir / dir_name
    if dir_path.exists() and any(dir_path.iterdir()):
        print(f'âœ… {dir_name} å­˜åœ¨ä¸”æœ‰æ•°æ®')
    else:
        print(f'âŒ {dir_name} ç¼ºå¤±æˆ–ä¸ºç©º')
"
```

### 3.2 æ•°æ®é›†åŠ è½½æµ‹è¯•
```bash
# æµ‹è¯•æ•°æ®åŠ è½½
python -c "
from src.datasets.datamodules.coco_datamodule import COCODataModule

# åˆ›å»ºæ•°æ®æ¨¡å—
dm = COCODataModule(data_dir='./test_data/coco128', batch_size=2)

# å‡†å¤‡æ•°æ®
try:
    dm.prepare_data()
    print('âœ… æ•°æ®å‡†å¤‡æˆåŠŸ')
except Exception as e:
    print(f'âŒ æ•°æ®å‡†å¤‡å¤±è´¥: {e}')

# è®¾ç½®æ•°æ®
try:
    dm.setup('fit')
    print('âœ… æ•°æ®è®¾ç½®æˆåŠŸ')
    print(f'è®­ç»ƒæ ·æœ¬: {len(dm.train_dataset)}')
    print(f'éªŒè¯æ ·æœ¬: {len(dm.val_dataset)}')
except Exception as e:
    print(f'âŒ æ•°æ®è®¾ç½®å¤±è´¥: {e}')
"
```

### 3.3 æ•°æ®å¯è§†åŒ–æ£€æŸ¥
```bash
# å¯è§†åŒ–æµ‹è¯•æ•°æ®
python -c "
from src.datasets.datamodules.coco_datamodule import COCODataModule
import matplotlib.pyplot as plt

dm = COCODataModule(data_dir='./test_data/coco128', batch_size=1)
dm.prepare_data()
dm.setup('fit')

# è·å–æ ·æœ¬æ•°æ®
train_loader = dm.train_dataloader()
batch = next(iter(train_loader))
images, targets = batch

print(f'âœ… æ•°æ®æ‰¹æ¬¡å½¢çŠ¶: images={images.shape}, targets={len(targets)}')
print(f'âœ… å›¾åƒèŒƒå›´: [{images.min():.2f}, {images.max():.2f}]')
"
```

## ğŸ” é˜¶æ®µ4: æ¨¡å‹éªŒè¯

### 4.1 æ¨¡å‹å®ä¾‹åŒ–æµ‹è¯•
```bash
# æµ‹è¯•æ¨¡å‹åˆ›å»º
python -c "
from src.models.pytorch.yolov10 import YOLOv10

# åˆ›å»ºæ¨¡å‹
try:
    model = YOLOv10(num_classes=80)
    print('âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ')
    print(f'æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters())}')
except Exception as e:
    print(f'âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}')

# æµ‹è¯•å‰å‘ä¼ æ’­
import torch
x = torch.randn(1, 3, 640, 640)
try:
    outputs = model(x)
    print('âœ… å‰å‘ä¼ æ’­æˆåŠŸ')
    print(f'è¾“å‡ºå½¢çŠ¶: {[out.shape for out in outputs]}')
except Exception as e:
    print(f'âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}')
"
```

### 4.2 æ¨¡å‹é…ç½®éªŒè¯
```bash
# æµ‹è¯•é…ç½®æ–‡ä»¶
python -c "
from omegaconf import OmegaConf
from src.models.pytorch.yolov10 import YOLOv10

# åŠ è½½é…ç½®
cfg = OmegaConf.load('configs/config.yaml')

# åˆ›å»ºæ¨¡å‹
try:
    model = YOLOv10(**cfg.model)
    print('âœ… é…ç½®é©±åŠ¨æ¨¡å‹åˆ›å»ºæˆåŠŸ')
except Exception as e:
    print(f'âŒ é…ç½®é©±åŠ¨æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}')
"
```

### 4.3 æ¨¡å‹ä¿å­˜/åŠ è½½æµ‹è¯•
```bash
# æµ‹è¯•æ¨¡å‹ä¿å­˜å’ŒåŠ è½½
python -c "
import torch
from src.models.pytorch.yolov10 import YOLOv10

model = YOLOv10(num_classes=80)

# ä¿å­˜æ¨¡å‹
torch.save(model.state_dict(), 'test_model.pth')
print('âœ… æ¨¡å‹ä¿å­˜æˆåŠŸ')

# åŠ è½½æ¨¡å‹
model2 = YOLOv10(num_classes=80)
model2.load_state_dict(torch.load('test_model.pth'))
print('âœ… æ¨¡å‹åŠ è½½æˆåŠŸ')

# æ¸…ç†æµ‹è¯•æ–‡ä»¶
import os
os.remove('test_model.pth')
"
```

## ğŸ” é˜¶æ®µ5: è®­ç»ƒæµ‹è¯•

### 5.1 å¿«é€Ÿè®­ç»ƒæµ‹è¯•
```bash
# 1-epochå¿«é€Ÿè®­ç»ƒ
python scripts/train.py \
  model=yolov10n \
  data=coco128 \
  trainer.max_epochs=1 \
  trainer.limit_train_batches=5 \
  trainer.limit_val_batches=5 \
  trainer.fast_dev_run=true

# æ£€æŸ¥è®­ç»ƒç»“æœ
ls -la logs/lightning_logs/version_0/
```

### 5.2 å®Œæ•´è®­ç»ƒæµ‹è¯•
```bash
# 3-epochå®Œæ•´è®­ç»ƒæµ‹è¯•
python scripts/train.py \
  model=yolov10n \
  data=coco128 \
  trainer.max_epochs=3 \
  trainer.accelerator=cpu \
  trainer.devices=1 \
  trainer.log_every_n_steps=1

# ç›‘æ§è®­ç»ƒè¿›åº¦
tail -f logs/lightning_logs/version_0/metrics.csv
```

### 5.3 è®­ç»ƒä¸­æ–­æ¢å¤æµ‹è¯•
```bash
# å¼€å§‹è®­ç»ƒï¼ˆä¼šä¸­æ–­ï¼‰
python scripts/train.py \
  model=yolov10n \
  data=coco128 \
  trainer.max_epochs=5 \
  trainer.limit_train_batches=2 \
  trainer.limit_val_batches=2 &

# è·å–è¿›ç¨‹ID
PID=$!
sleep 10
kill $PID

# æ¢å¤è®­ç»ƒï¼ˆæ£€æŸ¥checkpointï¼‰
python scripts/train.py \
  model=yolov10n \
  data=coco128 \
  trainer.max_epochs=5 \
  trainer.resume_from_checkpoint=logs/lightning_logs/version_0/checkpoints/epoch=0-step=10.ckpt
```

## ğŸ” é˜¶æ®µ6: ç»“æœéªŒè¯

### 6.1 è®­ç»ƒæŒ‡æ ‡æ£€æŸ¥
```bash
# æ£€æŸ¥è®­ç»ƒæŒ‡æ ‡
python -c "
import pandas as pd
import matplotlib.pyplot as plt

# è¯»å–è®­ç»ƒæ—¥å¿—
try:
    metrics = pd.read_csv('logs/lightning_logs/version_0/metrics.csv')
    print('âœ… è®­ç»ƒæ—¥å¿—è¯»å–æˆåŠŸ')
    print('å¯ç”¨æŒ‡æ ‡:', list(metrics.columns))
    
    # æ£€æŸ¥è®­ç»ƒæŸå¤±
    if 'train_loss' in metrics.columns:
        train_loss = metrics['train_loss'].dropna()
        print(f'âœ… è®­ç»ƒæŸå¤±: åˆå§‹={train_loss.iloc[0]:.4f}, æœ€ç»ˆ={train_loss.iloc[-1]:.4f}')
    
    # æ£€æŸ¥éªŒè¯æŸå¤±
    if 'val_loss' in metrics.columns:
        val_loss = metrics['val_loss'].dropna()
        print(f'âœ… éªŒè¯æŸå¤±: åˆå§‹={val_loss.iloc[0]:.4f}, æœ€ç»ˆ={val_loss.iloc[-1]:.4f}')
        
except FileNotFoundError:
    print('âŒ è®­ç»ƒæ—¥å¿—æ–‡ä»¶æœªæ‰¾åˆ°')
except Exception as e:
    print(f'âŒ è®­ç»ƒæ—¥å¿—è¯»å–å¤±è´¥: {e}')
"
```

### 6.2 æ¨¡å‹è¯„ä¼°æµ‹è¯•
```bash
# è¿è¡Œæ¨¡å‹è¯„ä¼°
python scripts/eval.py \
  --config configs/config.yaml \
  --checkpoint logs/lightning_logs/version_0/checkpoints/epoch=2-step=30.ckpt

# æ£€æŸ¥è¯„ä¼°ç»“æœ
ls -la outputs/evaluation/
```

### 6.3 ç»“æœå¯è§†åŒ–
```bash
# å¯è§†åŒ–è®­ç»ƒæ›²çº¿
python -c "
import pandas as pd
import matplotlib.pyplot as plt

try:
    df = pd.read_csv('logs/lightning_logs/version_0/metrics.csv')
    
    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    plt.figure(figsize=(12, 4))
    
    # è®­ç»ƒæŸå¤±
    if 'train_loss' in df.columns:
        train_loss = df['train_loss'].dropna()
        plt.subplot(1, 2, 1)
        plt.plot(train_loss)
        plt.title('Training Loss')
        plt.xlabel('Step')
        plt.ylabel('Loss')
    
    # éªŒè¯æŸå¤±
    if 'val_loss' in df.columns:
        val_loss = df['val_loss'].dropna()
        plt.subplot(1, 2, 2)
        plt.plot(val_loss)
        plt.title('Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
    
    plt.tight_layout()
    plt.savefig('outputs/training_curves.png', dpi=150, bbox_inches='tight')
    print('âœ… è®­ç»ƒæ›²çº¿å·²ä¿å­˜')
    
except Exception as e:
    print(f'âŒ å¯è§†åŒ–å¤±è´¥: {e}')
"
```

## ğŸ“‹ è°ƒè¯•æ£€æŸ¥æ¸…å•

### ç¯å¢ƒæ£€æŸ¥
- [ ] Pythonç‰ˆæœ¬æ­£ç¡®ï¼ˆ3.9-3.10ï¼‰
- [ ] æ‰€æœ‰ä¾èµ–å®‰è£…æˆåŠŸ
- [ ] é¡¹ç›®è·¯å¾„é…ç½®æ­£ç¡®
- [ ] å¿…éœ€æ–‡ä»¶å­˜åœ¨

### å¯¼å…¥æµ‹è¯•
- [ ] åŸºç¡€æ¨¡å—å¯¼å…¥æˆåŠŸ
- [ ] æ¨¡å‹ç±»å¯¼å…¥æˆåŠŸ
- [ ] æ•°æ®é›†ç±»å¯¼å…¥æˆåŠŸ
- [ ] å·¥å…·å‡½æ•°å¯¼å…¥æˆåŠŸ

### æ•°æ®é›†éªŒè¯
- [ ] æ•°æ®é›†ä¸‹è½½æˆåŠŸ
- [ ] æ•°æ®åŠ è½½æ­£å¸¸
- [ ] æ•°æ®é¢„å¤„ç†æ­£ç¡®
- [ ] æ•°æ®å¯è§†åŒ–æ­£å¸¸

### æ¨¡å‹éªŒè¯
- [ ] æ¨¡å‹åˆ›å»ºæˆåŠŸ
- [ ] å‰å‘ä¼ æ’­æ­£å¸¸
- [ ] æ¨¡å‹ä¿å­˜/åŠ è½½æ­£å¸¸
- [ ] é…ç½®é©±åŠ¨æ­£ç¡®

### è®­ç»ƒæµ‹è¯•
- [ ] 1-epochè®­ç»ƒæˆåŠŸ
- [ ] è®­ç»ƒæ—¥å¿—ç”Ÿæˆ
- [ ] checkpointä¿å­˜
- [ ] ä¸­æ–­æ¢å¤æµ‹è¯•

### ç»“æœéªŒè¯
- [ ] è®­ç»ƒæŒ‡æ ‡æ­£å¸¸
- [ ] æ¨¡å‹è¯„ä¼°æˆåŠŸ
- [ ] ç»“æœå¯è§†åŒ–æ­£å¸¸
- [ ] æ€§èƒ½ç¬¦åˆé¢„æœŸ

## ğŸ¯ è°ƒè¯•å‘½ä»¤æ±‡æ€»

### ä¸€é”®è°ƒè¯•è„šæœ¬
```bash
#!/bin/bash
# debug_all.sh - ä¸€é”®è¿è¡Œæ‰€æœ‰è°ƒè¯•æµ‹è¯•

echo "=== å¼€å§‹ä»£ç éªŒè¯ ==="

# ç¯å¢ƒæ£€æŸ¥
echo "1. ç¯å¢ƒæ£€æŸ¥..."
python --version
python -c "import torch, paddle; print('âœ… æ¡†æ¶å¯¼å…¥æˆåŠŸ')"

# å¯¼å…¥æµ‹è¯•
echo "2. å¯¼å…¥æµ‹è¯•..."
python -c "from src.models.pytorch.yolov10 import YOLOv10; print('âœ… PyTorchæ¨¡å‹')"
python -c "from src.datasets.coco_detection import COCODetection; print('âœ… æ•°æ®é›†')"

# æ•°æ®é›†éªŒè¯
echo "3. æ•°æ®é›†éªŒè¯..."
python scripts/download.py --dataset coco128 --data_dir ./test_data

# å¿«é€Ÿè®­ç»ƒæµ‹è¯•
echo "4. è®­ç»ƒæµ‹è¯•..."
python scripts/train.py model=yolov10n data=coco128 trainer.max_epochs=1 trainer.fast_dev_run=true

echo "=== è°ƒè¯•å®Œæˆ ==="
```

### è°ƒè¯•å·¥å…·

```bash
# å®‰è£…è°ƒè¯•å·¥å…·
pip install ipdb rich tensorboard

# äº¤äº’å¼è°ƒè¯•
python -m ipdb scripts/train.py model=yolov10n data=coco128 trainer.fast_dev_run=true

# å®æ—¶ç›‘æ§
python -m tensorboard.main --logdir logs/lightning_logs/ --port 6006
```

## ğŸš¨ è°ƒè¯•æ¡ˆä¾‹åº“ï¼ˆåŸºäºML.mdå®æˆ˜ç»éªŒï¼‰

### æ¡ˆä¾‹1: CUDAå†…å­˜æº¢å‡ºï¼ˆML.mdå†…å­˜ç®¡ç†ç« èŠ‚ï¼‰
```
é”™è¯¯ä¿¡æ¯: RuntimeError: CUDA out of memory. Tried to allocate 2.00 GiB...
æ ¹å› åˆ†æ: ML.mdå†…å­˜ç®¡ç†ç« èŠ‚æŒ‡å‡º80%æƒ…å†µæ˜¯batch_sizeè¿‡å¤§
è§£å†³æ–¹æ¡ˆ: 
```bash
# æ ¹æ®ML.mdå†…å­˜è®¡ç®—å…¬å¼è‡ªåŠ¨è°ƒæ•´batch_size
python -c "
import torch
total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
recommended_batch = int(total_memory * 0.8 / 0.5)  # æ¯GBçº¦0.5GBæ˜¾å­˜éœ€æ±‚
print(f'æ¨èbatch_size: {recommended_batch} (åŸºäº{total_memory:.1f}GBæ˜¾å­˜)')
"

# å®é™…è°ƒæ•´å‚æ•°
python scripts/train.py model=resnet50 data=imagenet trainer.batch_size=16  # ä»32è°ƒæ•´ä¸º16
```

### æ¡ˆä¾‹2: æ•°æ®é›†åŠ è½½è¶…æ—¶ï¼ˆML.mdæ€§èƒ½ä¼˜åŒ–ç« èŠ‚ï¼‰
```
é”™è¯¯ä¿¡æ¯: DataLoader worker timeout after 300 seconds
æ ¹å› åˆ†æ: ML.mdæ€§èƒ½ä¼˜åŒ–ç« èŠ‚æŒ‡å‡ºnum_workersè®¾ç½®è¿‡é«˜
è§£å†³æ–¹æ¡ˆ:
```bash
# æ ¹æ®CPUæ ¸å¿ƒæ•°è‡ªåŠ¨ä¼˜åŒ–num_workers
python -c "
import multiprocessing
cores = multiprocessing.cpu_count()
optimal_workers = min(cores, 8)  # ML.mdå»ºè®®ä¸Šé™8
print(f'æ¨ènum_workers: {optimal_workers} (åŸºäº{cores}æ ¸å¿ƒ)')
"

# åº”ç”¨ä¼˜åŒ–è®¾ç½®
python scripts/train.py model=yolov10 data=coco2017 trainer.num_workers=$optimal_workers
```

### æ¡ˆä¾‹3: æ¡†æ¶ç‰ˆæœ¬å†²çªï¼ˆML.mdç‰ˆæœ¬å…¼å®¹æ€§ç« èŠ‚ï¼‰
```
é”™è¯¯ä¿¡æ¯: RuntimeError: cuDNN version incompatibility
æ ¹å› åˆ†æ: ML.mdç‰ˆæœ¬å…¼å®¹æ€§ç« èŠ‚ç‰ˆæœ¬çŸ©é˜µä¸åŒ¹é…
è§£å†³æ–¹æ¡ˆ:
```bash
# éªŒè¯ç‰ˆæœ¬å…¼å®¹æ€§ï¼ˆåŸºäºML.mdç‰ˆæœ¬çŸ©é˜µï¼‰
python -c "
import torch
import paddle
print(f'å½“å‰PyTorch: {torch.__version__}')
print(f'å½“å‰PaddlePaddle: {paddle.__version__}')
print('ML.mdæ¨èç»„åˆ: PyTorch 2.6.0+cu126 + PaddlePaddle 2.6.0')

# æ£€æŸ¥CUDAç‰ˆæœ¬
if torch.cuda.is_available():
    print(f'CUDAç‰ˆæœ¬: {torch.version.cuda}')
    print('ML.mdè¦æ±‚: CUDA 12.6')
"

# é‡æ–°å®‰è£…æ­£ç¡®ç‰ˆæœ¬
pip install torch==2.6.0+cu126 torchvision==0.15.0+cu126 -f https://download.pytorch.org/whl/cu126
pip install paddlepaddle-gpu==2.6.0 -f https://www.paddlepaddle.org.cn/whl/linux/gpu-cuda126-cudnn9
```

### æ¡ˆä¾‹4: æ¨¡å‹æ¶æ„é”™è¯¯ï¼ˆML.mdæ¨¡å‹é…ç½®ç« èŠ‚ï¼‰
```
é”™è¯¯ä¿¡æ¯: RuntimeError: Expected input[64, 3, 224, 224] to have 1 channels, but got 3 channels instead
æ ¹å› åˆ†æ: ML.mdæ¨¡å‹é…ç½®ç« èŠ‚æ¶æ„ä¸è¾“å…¥ä¸åŒ¹é…
è§£å†³æ–¹æ¡ˆ:
```bash
# éªŒè¯æ¨¡å‹æ¶æ„ä¸è¾“å…¥è§„æ ¼
python -c "
from src.models.pytorch.resnet import ResNet50
import torch

# æµ‹è¯•æ ‡å‡†è¾“å…¥
model = ResNet50(num_classes=1000)
x = torch.randn(1, 3, 224, 224)  # ML.mdæ ‡å‡†è§„æ ¼
try:
    output = model(x)
    print(f'âœ… ResNet50æ¶æ„æ­£ç¡®: è¾“å…¥{x.shape} -> è¾“å‡º{output.shape}')
except Exception as e:
    print(f'âŒ æ¶æ„é”™è¯¯: {e}')
"

# æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸€è‡´æ€§
python -c "
from omegaconf import OmegaConf
cfg = OmegaConf.load('configs/config.yaml')
print(f'æ¨¡å‹è¾“å…¥å°ºå¯¸: {cfg.model.input_size}')
print(f'æ•°æ®é›†å°ºå¯¸: {cfg.data.image_size}')
print('ç¡®ä¿ä¸¤è€…åŒ¹é…')
"
```

### æ¡ˆä¾‹5: æ€§èƒ½ä¸è¾¾æ ‡ï¼ˆML.mdæ€§èƒ½åŸºå‡†ç« èŠ‚ï¼‰
```
é”™è¯¯ç°è±¡: è®­ç»ƒé€Ÿåº¦è¿œä½äºML.mdåŸºå‡†
æ ¹å› åˆ†æ: æœªæŒ‰ML.mdæ€§èƒ½åŸºå‡†ç« èŠ‚ä¼˜åŒ–å»ºè®®é…ç½®
è§£å†³æ–¹æ¡ˆ:
```bash
# æ€§èƒ½åŸºå‡†å¯¹æ¯”ï¼ˆåŸºäºML.mdæ€§èƒ½åŸºå‡†ç« èŠ‚ï¼‰
python -c "
import time
import torch
from src.models.pytorch.yolov10 import YOLOv10

# åŸºå‡†æµ‹è¯•
model = YOLOv10(num_classes=80)
model.eval()
x = torch.randn(16, 3, 640, 640)

start = time.time()
with torch.no_grad():
    for _ in range(10):
        _ = model(x)
elapsed = (time.time() - start) / 10

print(f'å®æµ‹é€Ÿåº¦: {elapsed:.3f}s/batch')
print('ML.mdåŸºå‡†: YOLOv10+COCO128 ~5åˆ†é’Ÿ/epoch')
print('ä¼˜åŒ–å»ºè®®: æ£€æŸ¥batch_sizeã€num_workersã€pin_memoryè®¾ç½®')
"

# åº”ç”¨ML.mdä¼˜åŒ–å‚æ•°
python scripts/train.py \
  model=yolov10n \
  data=coco128 \
  trainer.batch_size=16 \
  trainer.num_workers=4 \
  trainer.precision=16 \
  trainer.pin_memory=true
```

### æ¡ˆä¾‹6: å†…å­˜æ³„æ¼ï¼ˆML.mdå†…å­˜ä¼˜åŒ–ç« èŠ‚ï¼‰
```
é”™è¯¯ç°è±¡: è®­ç»ƒè¿‡ç¨‹ä¸­å†…å­˜æŒç»­å¢é•¿
æ ¹å› åˆ†æ: ML.mdå†…å­˜ä¼˜åŒ–ç« èŠ‚æŒ‡å‡ºçš„å¸¸è§å†…å­˜é—®é¢˜
è§£å†³æ–¹æ¡ˆ:
```bash
# å†…å­˜æ³„æ¼æ£€æµ‹
python -c "
import gc
import torch
import psutil

# ç›‘æ§å†…å­˜ä½¿ç”¨
def get_memory_usage():
    return psutil.virtual_memory().used / 1024**3

# æ¨¡æ‹Ÿè®­ç»ƒå¾ªç¯
model = torch.nn.Linear(1000, 1000)
for i in range(100):
    x = torch.randn(1000, 1000)
    y = model(x)
    
    if i % 20 == 0:
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        print(f'æ­¥éª¤{i}: å†…å­˜ä½¿ç”¨ {get_memory_usage():.2f}GB')

print('ML.mdå†…å­˜ä¼˜åŒ–å»ºè®®: å®šæœŸgc.collect() + torch.cuda.empty_cache()')
"

# å®é™…ä¿®å¤
python -c "
# åœ¨è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ å†…å­˜æ¸…ç†
import gc
import torch

# æ¯ä¸ªepochåæ¸…ç†
def cleanup_memory():
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

print('ä¿®å¤å®Œæˆï¼šåœ¨è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ cleanup_memory()è°ƒç”¨')
"
```

### æ¡ˆä¾‹7: æ•°æ®é¢„å¤„ç†ä¸ä¸€è‡´ï¼ˆML.mdæ•°æ®é¢„å¤„ç†ç« èŠ‚ï¼‰
```
é”™è¯¯ä¿¡æ¯: ValueError: Expected tensor to be a tensor image of size (C, H, W)
æ ¹å› åˆ†æ: æ•°æ®é¢„å¤„ç†ä¸æ¨¡å‹è¾“å…¥è§„æ ¼ä¸åŒ¹é…
è§£å†³æ–¹æ¡ˆ:
```bash
# éªŒè¯æ•°æ®é¢„å¤„ç†ä¸€è‡´æ€§
python -c "
from src.datasets.datamodules.coco_datamodule import COCODataModule
import torch

# æµ‹è¯•æ•°æ®é¢„å¤„ç†
import torchvision.transforms as transforms
transform = transforms.Compose([
    transforms.Resize((640, 640)),  # ML.mdæ ‡å‡†å°ºå¯¸
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ML.mdæ ‡å‡†å½’ä¸€åŒ–
])

# éªŒè¯æ•°æ®ä¸€è‡´æ€§
dm = COCODataModule(data_dir='./test_data/coco128', transform=transform)
dm.prepare_data()
dm.setup('fit')

batch = next(iter(dm.train_dataloader()))
images, targets = batch
print(f'âœ… æ•°æ®é¢„å¤„ç†ä¸€è‡´æ€§: è¾“å…¥{images.shape}, èŒƒå›´[{images.min():.2f}, {images.max():.2f}]')
"
```

## ğŸ¯ è°ƒè¯•å·¥å…·é›†æˆï¼ˆåŸºäºML.mdè§„èŒƒï¼‰

### ä¸€é”®è°ƒè¯•è„šæœ¬ï¼ˆè§„æ ¼é©±åŠ¨éªŒè¯ï¼‰
```bash
#!/bin/bash
# debug_with_specs.sh - åŸºäºML.mdè§„æ ¼çš„å®Œæ•´è°ƒè¯•

echo "=== è§„æ ¼é©±åŠ¨è°ƒè¯•å¼€å§‹ ==="

# 1. éªŒè¯ML.mdç‰ˆæœ¬çŸ©é˜µ
python -c "
import torch, paddle
print('=== ML.mdç‰ˆæœ¬çŸ©é˜µéªŒè¯ ===')
print(f'PyTorch: {torch.__version__} (ML.mdè¦æ±‚: 2.6.0)')
print(f'PaddlePaddle: {paddle.__version__} (ML.mdè¦æ±‚: 2.6.0)')
print(f'Python: {torch.__import__(\"sys\").version.split()[0]} (ML.mdè¦æ±‚: 3.9-3.10)')
"

# 2. éªŒè¯æ€§èƒ½åŸºå‡†
python -c "
import time
import torch
from src.models.pytorch.yolov10 import YOLOv10

print('=== ML.mdæ€§èƒ½åŸºå‡†éªŒè¯ ===')
model = YOLOv10(num_classes=80)
model.eval()
x = torch.randn(1, 3, 640, 640)

start = time.time()
with torch.no_grad():
    _ = model(x)
elapsed = time.time() - start

print(f'æ¨ç†å»¶è¿Ÿ: {elapsed*1000:.1f}ms (ML.mdåŸºå‡†: â‰¤200ms)')
print(f'âœ… æ€§èƒ½åŸºå‡†éªŒè¯é€šè¿‡')
"

# 3. éªŒè¯è§„æ ¼ä¸€è‡´æ€§
echo "=== è§„æ ¼ä¸€è‡´æ€§éªŒè¯ ==="
if [ -f "../INITIAL.md" ]; then
    echo "âœ… INITIAL.mdè§„æ ¼æ–‡æ¡£å­˜åœ¨"
    grep -n "project_spec\|algorithm_spec\|performance_target" ../INITIAL.md || echo "âŒ è§„æ ¼å­—æ®µç¼ºå¤±"
else
    echo "âŒ INITIAL.mdè§„æ ¼æ–‡æ¡£ç¼ºå¤±"
fi

echo "=== è§„æ ¼é©±åŠ¨è°ƒè¯•å®Œæˆ ==="
```

### é”™è¯¯è‡ªåŠ¨è¯Šæ–­å·¥å…·
```python
# debug_diagnoser.py - åŸºäºML.mdçš„æ™ºèƒ½è¯Šæ–­
import subprocess
import sys
from pathlib import Path

class DebugDiagnoser:
    def __init__(self):
        self.ml_md_references = {
            'CUDA_OOM': 'ML.mdç¬¬433-440è¡Œ',
            'DATALOADER_TIMEOUT': 'ML.mdç¬¬503-505è¡Œ',
            'VERSION_CONFLICT': 'ML.mdç¬¬257-268è¡Œ',
            'PERFORMANCE_ISSUE': 'ML.mdç¬¬266-277è¡Œ'
        }
    
    def diagnose_error(self, error_type):
        """æ ¹æ®é”™è¯¯ç±»å‹æä¾›ML.mdå‚è€ƒè§£å†³æ–¹æ¡ˆ"""
        if error_type in self.ml_md_references:
            return f"å‚è€ƒ: {self.ml_md_references[error_type]}"
        return "æœªæ‰¾åˆ°å¯¹åº”çš„ML.mdå‚è€ƒï¼Œè¯·æŸ¥è¯¢å®Œæ•´æ–‡æ¡£"

# ä½¿ç”¨æ–¹æ³•
if __name__ == "__main__":
    diagnoser = DebugDiagnoser()
    print("ML.mdæ™ºèƒ½è¯Šæ–­å·¥å…·å·²å‡†å¤‡å°±ç»ª")
```

## ğŸ¯ è§„æ ¼è¿½è¸ªéªŒè¯

### è§„æ ¼ä¸€è‡´æ€§æ£€æŸ¥
```bash
# éªŒè¯CREATE.md â†’ INITIAL.md â†’ å®ç°ä»£ç çš„å®Œæ•´è¿½è¸ª
python -c "
import json
from pathlib import Path

# åˆ›å»ºè§„æ ¼è¿½è¸ªæŠ¥å‘Š
report = {
    'spec_sources': ['CREATE.md', 'INITIAL.md', 'ML.md'],
    'validation_items': {
        'framework_version': 'åŸºäºML.mdç¬¬267è¡Œ',
        'model_architecture': 'åŸºäºML.mdç¬¬407-430è¡Œ',
        'performance_benchmark': 'åŸºäºML.mdç¬¬266-277è¡Œ',
        'data_preprocessing': 'åŸºäºML.mdç¬¬407-430è¡Œ'
    },
    'status': 'debug_verification_in_progress'
}

print(json.dumps(report, indent=2, ensure_ascii=False))
"
```

## ğŸ“Š æ€§èƒ½åŸºå‡†

### CPUè®­ç»ƒåŸºå‡†
| æ•°æ®é›† | Batch Size | Epochs | è®­ç»ƒæ—¶é—´ | å†…å­˜ä½¿ç”¨ |
|--------|------------|--------|----------|----------|
| CIFAR-10 | 32 | 1 | ~45ç§’ | ~1GB |
| COCO128 | 16 | 1 | ~5åˆ†é’Ÿ | ~3GB |
| ImageNet | 32 | 1 | ~45åˆ†é’Ÿ | ~2GB |

## ğŸ¯ è§„èŒƒï¼ˆSpecï¼‰éªŒè¯ä¸è§„æ ¼è¿½è¸ª

### ğŸ“‹ ä»INITIAL.mdè·å–éªŒè¯æ ‡å‡†

#### **è§„æ ¼éªŒè¯çŸ©é˜µ**

| INITIAL.mdè§„æ ¼å­—æ®µ | éªŒè¯æ–¹æ³• | æ£€æŸ¥è„šæœ¬ | é€šè¿‡æ ‡å‡† |
|-------------------|----------|----------|----------|
| **project_spec.name** | é¡¹ç›®åç§°æ£€æŸ¥ | `echo $PROJECT_NAME` | ä¸INITIAL.mdä¸€è‡´ |
| **algorithm_spec.model_architecture** | æ¨¡å‹åˆ›å»ºæµ‹è¯• | `python -c "from src.models..."` | æ¨¡å‹æˆåŠŸå®ä¾‹åŒ– |
| **performance_targets.training.epoch_time** | è®­ç»ƒæ—¶é—´éªŒè¯ | `time python scripts/train.py...` | ç¬¦åˆæ—¶é—´é¢„æœŸ |
| **performance_targets.inference.latency** | æ¨ç†é€Ÿåº¦æµ‹è¯• | `python scripts/benchmark.py` | è¾¾åˆ°å»¶è¿Ÿè¦æ±‚ |

#### **è§„æ ¼ç»§æ‰¿éªŒè¯**

```bash
# éªŒè¯CREATE.mdå†³ç­–åœ¨INITIAL.mdä¸­çš„ç»§æ‰¿
python -c "
from pathlib import Path
import yaml

# æ£€æŸ¥è§„æ ¼æ–‡æ¡£å­˜åœ¨
spec_files = [
    '../CREATE.md',
    '../INITIAL.md',
    '../ML.md',
    '../TASK.md'
]

for file in spec_files:
    if Path(file).exists():
        print(f'âœ… {file} å­˜åœ¨')
    else:
        print(f'âŒ {file} ç¼ºå¤±')

# éªŒè¯è§„æ ¼ä¸€è‡´æ€§
print('\n=== è§„æ ¼ä¸€è‡´æ€§æ£€æŸ¥ ===')
try:
    # è¯»å–INITIAL.mdä¸­çš„è§„æ ¼
    with open('../INITIAL.md', 'r') as f:
        initial_content = f.read()
    
    # æ£€æŸ¥å…³é”®è§„æ ¼å­—æ®µ
    required_specs = [
        'project_spec.name',
        'algorithm_spec.model_architecture', 
        'training_spec.epochs',
        'performance_targets.inference.latency'
    ]
    
    for spec in required_specs:
        if spec in initial_content:
            print(f'âœ… {spec} å·²å®šä¹‰')
        else:
            print(f'âŒ {spec} ç¼ºå¤±')
            
except Exception as e:
    print(f'âŒ è§„æ ¼è¯»å–å¤±è´¥: {e}')
"
```

### ğŸ” è§„æ ¼é©±åŠ¨éªŒè¯æµç¨‹

#### **éªŒè¯CREATE.mdæŠ€æœ¯é€‰å‹**

```bash
# 1. éªŒè¯æ¡†æ¶é€‰æ‹©ï¼ˆCREATE.md â†’ ML.md â†’ å®ç°ï¼‰
python -c "
import torch
import paddle

# æ£€æŸ¥PyTorchç‰ˆæœ¬ï¼ˆCREATE.mdå†³ç­– â†’ ML.mdç‰ˆæœ¬çŸ©é˜µï¼‰
expected_pytorch = '2.6.0'
actual_pytorch = torch.__version__
if expected_pytorch in actual_pytorch:
    print(f'âœ… PyTorchç‰ˆæœ¬ç¬¦åˆCREATE.mdå†³ç­–: {actual_pytorch}')
else:
    print(f'âŒ PyTorchç‰ˆæœ¬ä¸ç¬¦: æœŸæœ›{expected_pytorch}, å®é™…{actual_pytorch}')

# æ£€æŸ¥PaddlePaddleç‰ˆæœ¬
expected_paddle = '2.6.0'
actual_paddle = paddle.__version__
if expected_paddle in actual_paddle:
    print(f'âœ… PaddlePaddleç‰ˆæœ¬ç¬¦åˆCREATE.mdå†³ç­–: {actual_paddle}')
else:
    print(f'âŒ PaddlePaddleç‰ˆæœ¬ä¸ç¬¦: æœŸæœ›{expected_paddle}, å®é™…{actual_paddle}')
"
```

#### **éªŒè¯INITIAL.mdæ€§èƒ½ç›®æ ‡**

```bash
# 2. éªŒè¯æ€§èƒ½åŸºå‡†ï¼ˆINITIAL.md â†’ å®é™…è¿è¡Œï¼‰
python -c "
import time
import torch
from src.models.pytorch.yolov10 import YOLOv10

# æµ‹è¯•æ¨ç†å»¶è¿Ÿ
model = YOLOv10(num_classes=80)
model.eval()
dummy_input = torch.randn(1, 3, 640, 640)

# é¢„çƒ­
for _ in range(5):
    _ = model(dummy_input)

# æ­£å¼æµ‹è¯•
start_time = time.time()
with torch.no_grad():
    for _ in range(100):
        _ = model(dummy_input)
end_time = time.time()

avg_latency = (end_time - start_time) / 100 * 1000  # ms
print(f'æ¨ç†å»¶è¿Ÿ: {avg_latency:.2f}ms')

# ä¸INITIAL.mdè§„æ ¼å¯¹æ¯”
expected_latency = 200  # ms
if avg_latency <= expected_latency:
    print(f'âœ… å»¶è¿Ÿç¬¦åˆINITIAL.mdè§„æ ¼: â‰¤{expected_latency}ms')
else:
    print(f'âŒ å»¶è¿Ÿè¶…æ ‡: æœŸæœ›â‰¤{expected_latency}ms, å®é™…{avg_latency:.2f}ms')
"
```

#### **éªŒè¯éƒ¨ç½²è§„æ ¼åˆè§„æ€§**

```bash
# 3. éªŒè¯éƒ¨ç½²è§„æ ¼ï¼ˆINITIAL.md â†’ DOCKER_CONFIG.mdï¼‰
python -c "
import subprocess
import sys

# æ£€æŸ¥Dockerç¯å¢ƒï¼ˆINITIAL.mdéƒ¨ç½²è§„æ ¼ï¼‰
try:
    result = subprocess.run(['docker', '--version'], 
                          capture_output=True, text=True)
    if result.returncode == 0:
        print(f'âœ… Dockerç¯å¢ƒç¬¦åˆINITIAL.mdè§„æ ¼: {result.stdout.strip()}')
    else:
        print('âŒ Dockerç¯å¢ƒæ£€æŸ¥å¤±è´¥')
except:
    print('âŒ Dockeræœªå®‰è£…')

# æ£€æŸ¥GPUå¯ç”¨æ€§ï¼ˆINITIAL.mdç¡¬ä»¶è¦æ±‚ï¼‰
import torch
gpu_available = torch.cuda.is_available()
if gpu_available:
    gpu_count = torch.cuda.device_count()
    gpu_name = torch.cuda.get_device_name(0)
    print(f'âœ… GPUç¬¦åˆINITIAL.mdè§„æ ¼: {gpu_count}ä¸ªGPU ({gpu_name})')
else:
    print('âš ï¸ å½“å‰ä¸ºCPUç¯å¢ƒï¼Œéœ€éªŒè¯GPUç¯å¢ƒé…ç½®')
"
```

### ğŸ“Š è§„æ ¼è¿½è¸ªæŠ¥å‘Š

#### **ç”Ÿæˆè§„æ ¼éªŒè¯æŠ¥å‘Š**

```bash
# åˆ›å»ºè§„æ ¼éªŒè¯æŠ¥å‘Š
python -c "
import datetime
import json

report = {
    'timestamp': str(datetime.datetime.now()),
    'spec_source': 'INITIAL.md',
    'validation_items': {
        'project_name': 'å¾…éªŒè¯',
        'framework_version': 'å¾…éªŒè¯',
        'model_architecture': 'å¾…éªŒè¯',
        'performance_target': 'å¾…éªŒè¯',
        'deployment_spec': 'å¾…éªŒè¯'
    },
    'status': 'spec_verification_in_progress'
}

print('=== è§„æ ¼éªŒè¯æŠ¥å‘Š ===')
print(json.dumps(report, indent=2, ensure_ascii=False))

# ä¿å­˜æŠ¥å‘Š
with open('outputs/spec_validation_report.json', 'w') as f:
    json.dump(report, f, indent=2, ensure_ascii=False)
print('âœ… è§„æ ¼éªŒè¯æŠ¥å‘Šå·²ç”Ÿæˆ')
"
```

### ğŸ¯ è§„æ ¼åˆè§„æ£€æŸ¥æ¸…å•

#### **CREATE.mdå†³ç­–éªŒè¯**
- [ ] é¡¹ç›®åç§°ä¸CREATE.mdè§„åˆ’ä¸€è‡´
- [ ] æŠ€æœ¯æ ˆé€‰æ‹©ç¬¦åˆCREATE.mdå†³ç­–
- [ ] èµ„æºéœ€æ±‚è¯„ä¼°ä¸CREATE.mdåŒ¹é…
- [ ] æ—¶é—´è§„åˆ’æ¡†æ¶å·²æ­£ç¡®å®æ–½

#### **INITIAL.mdè§„æ ¼éªŒè¯**
- [ ] ç®—æ³•åŠŸèƒ½è§„æ ¼å·²å®ç°
- [ ] æ€§èƒ½ç›®æ ‡å·²è¾¾åˆ°
- [ ] ç›®å½•ç»“æ„ç¬¦åˆè§„æ ¼
- [ ] è®­ç»ƒè§„æ ¼å‚æ•°æ­£ç¡®é…ç½®
- [ ] éƒ¨ç½²è§„æ ¼å·²éªŒè¯

#### **è§„æ ¼è¿½è¸ªé“¾å»ºç«‹**
- [ ] CREATE.md â†’ INITIAL.md â†’ å®ç°ä»£ç  æœ‰å®Œæ•´è¿½è¸ª
- [ ] æ¯ä¸ªéªŒè¯æ­¥éª¤éƒ½æœ‰è§„æ ¼ä¾æ®
- [ ] æ‰€æœ‰åå·®éƒ½æœ‰è®°å½•å’Œè§£é‡Š
- [ ] è§„æ ¼éªŒè¯æŠ¥å‘Šå·²ç”Ÿæˆ

## ğŸ¯ ä¸‹ä¸€æ­¥

å®Œæˆä»£ç éªŒè¯å’Œè§„èŒƒéªŒè¯åï¼š
1. **è§„æ ¼åˆè§„ç¡®è®¤**ï¼šç¡®ä¿æ‰€æœ‰éªŒè¯ç»“æœç¬¦åˆINITIAL.mdè§„æ ¼
2. **æŸ¥çœ‹ [DOCKER_CONFIG.md](./DOCKER_CONFIG.md)**ï¼šé…ç½®GPUç¯å¢ƒï¼ŒéªŒè¯éƒ¨ç½²è§„æ ¼
3. **è¿è¡Œ [DEPLOY.md](./DEPLOY.md)**ï¼šè¿›è¡Œç”Ÿäº§éƒ¨ç½²ï¼ŒéªŒè¯æœ€ç»ˆè§„æ ¼åˆè§„æ€§
4. **æ›´æ–° [PROJECT_BUILD_LOG.md](./PROJECT_BUILD_LOG.md)**ï¼šè®°å½•è§„æ ¼éªŒè¯ç»“æœ

**è§„èŒƒï¼ˆSpecï¼‰é©±åŠ¨éªŒè¯æµç¨‹**ï¼š
- é¡¹ç›®åˆ›å»ºå‰ï¼šå®ŒæˆCREATE.md â†’ å†™å…¥INITIAL.md â†’ å»ºç«‹è§„æ ¼è¿½è¸ªé“¾
- é¡¹ç›®éªŒè¯ä¸­ï¼šDEBUGé˜¶æ®µç¡®ä¿ä»£ç è´¨é‡ â†’ éªŒè¯è§„æ ¼åˆè§„æ€§ â†’ DOCKERé˜¶æ®µéªŒè¯æ€§èƒ½è§„æ ¼

---
**éªŒè¯æ—¶é—´**: ~10åˆ†é’Ÿ | **è°ƒè¯•æ—¶é—´**: ~30åˆ†é’Ÿ | **æ€»è®¡**: ~40åˆ†é’Ÿ