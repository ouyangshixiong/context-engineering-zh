# ğŸ› ä»£ç éªŒè¯æ£€æŸ¥æ¸…å•

> ç³»ç»ŸåŒ–çš„ä»£ç éªŒè¯æµç¨‹ï¼Œç¡®ä¿ç”Ÿæˆä»£ç çš„æ­£ç¡®æ€§å’Œå¯ç”¨æ€§

## ğŸ¯ éªŒè¯æµç¨‹å›¾

```mermaid
flowchart TD
    A[å¼€å§‹è°ƒè¯•] --> B[ç¯å¢ƒæ£€æŸ¥]
    B --> C[å¯¼å…¥æµ‹è¯•]
    C --> D[æ•°æ®é›†éªŒè¯]
    D --> E[æ¨¡å‹éªŒè¯]
    E --> F[è®­ç»ƒæµ‹è¯•]
    F --> G[ç»“æœéªŒè¯]
    G --> H{å…¨éƒ¨é€šè¿‡?}
    H -->|å¦| I[é—®é¢˜ä¿®å¤]
    I --> B
    H -->|æ˜¯| J[è°ƒè¯•å®Œæˆ]
    
    style B fill:#90EE90,stroke:#333
    style F fill:#FFB6C1,stroke:#333
    style J fill:#90EE90,stroke:#333
```

## ğŸ” é˜¶æ®µ1: ç¯å¢ƒæ£€æŸ¥

### 1.1 Pythonç¯å¢ƒéªŒè¯
```bash
# æ£€æŸ¥Pythonç‰ˆæœ¬
python --version  # æœŸæœ›: 3.9-3.10

# æ£€æŸ¥ä¾èµ–ç‰ˆæœ¬
python -c "
import torch, paddle, pytorch_lightning
print(f'PyTorch: {torch.__version__}')
print(f'PaddlePaddle: {paddle.__version__}')
print(f'PyTorch Lightning: {pytorch_lightning.__version__}')
"
```

### 1.2 é¡¹ç›®è·¯å¾„æ£€æŸ¥
```bash
# æ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•
pwd  # åº”è¯¥åœ¨é¡¹ç›®æ ¹ç›®å½•

# æ£€æŸ¥PYTHONPATH
python -c "import sys; print('PYTHONPATH:', sys.path)"

# è®¾ç½®é¡¹ç›®è·¯å¾„
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
```

### 1.3 æ–‡ä»¶ç»“æ„æ£€æŸ¥
```bash
# æ£€æŸ¥å¿…éœ€æ–‡ä»¶
required_files=(
    "src/__init__.py"
    "src/models/__init__.py"
    "src/datasets/__init__.py"
    "scripts/train.py"
    "scripts/eval.py"
    "configs/config.yaml"
)

for file in "${required_files[@]}"; do
    if [ -f "$file" ]; then
        echo "âœ… $file"
    else
        echo "âŒ $file ç¼ºå¤±"
    fi
done
```

## ğŸ” é˜¶æ®µ2: å¯¼å…¥æµ‹è¯•

### 2.1 åŸºç¡€æ¨¡å—å¯¼å…¥
```bash
# æµ‹è¯•æ ¸å¿ƒæ¨¡å—å¯¼å…¥
python -c "
try:
    import src.models
    print('âœ… modelsæ¨¡å—å¯¼å…¥æˆåŠŸ')
except ImportError as e:
    print(f'âŒ modelsæ¨¡å—å¯¼å…¥å¤±è´¥: {e}')

try:
    import src.datasets
    print('âœ… datasetsæ¨¡å—å¯¼å…¥æˆåŠŸ')
except ImportError as e:
    print(f'âŒ datasetsæ¨¡å—å¯¼å…¥å¤±è´¥: {e}')
"
```

### 2.2 å…·ä½“ç±»å¯¼å…¥æµ‹è¯•
```bash
# æµ‹è¯•æ¨¡å‹ç±»å¯¼å…¥
python -c "
try:
    from src.models.pytorch.yolov10 import YOLOv10
    print('âœ… PyTorch YOLOv10æ¨¡å‹å¯¼å…¥æˆåŠŸ')
except ImportError as e:
    print(f'âŒ PyTorch YOLOv10æ¨¡å‹å¯¼å…¥å¤±è´¥: {e}')

try:
    from src.models.paddle.yolov10 import YOLOv10
    print('âœ… PaddlePaddle YOLOv10æ¨¡å‹å¯¼å…¥æˆåŠŸ')
except ImportError as e:
    print(f'âŒ PaddlePaddle YOLOv10æ¨¡å‹å¯¼å…¥å¤±è´¥: {e}')
"
```

### 2.3 æ•°æ®é›†å¯¼å…¥æµ‹è¯•
```bash
# æµ‹è¯•æ•°æ®é›†å¯¼å…¥
python -c "
try:
    from src.datasets.coco_detection import COCODetection
    print('âœ… COCOæ•°æ®é›†å¯¼å…¥æˆåŠŸ')
except ImportError as e:
    print(f'âŒ COCOæ•°æ®é›†å¯¼å…¥å¤±è´¥: {e}')

try:
    from src.datasets.datamodules.coco_datamodule import COCODataModule
    print('âœ… COCOæ•°æ®æ¨¡å—å¯¼å…¥æˆåŠŸ')
except ImportError as e:
    print(f'âŒ COCOæ•°æ®æ¨¡å—å¯¼å…¥å¤±è´¥: {e}')
"
```

## ğŸ” é˜¶æ®µ3: æ•°æ®é›†éªŒè¯

### 3.1 æ•°æ®é›†ä¸‹è½½éªŒè¯
```bash
# ä¸‹è½½æµ‹è¯•æ•°æ®é›†
python scripts/download.py --dataset coco128 --data_dir ./test_data

# éªŒè¯æ•°æ®é›†å®Œæ•´æ€§
python -c "
import os
from pathlib import Path

# æ£€æŸ¥æ•°æ®é›†ç›®å½•
data_dir = Path('./test_data/coco128')
required_dirs = ['train2017', 'val2017', 'annotations']

for dir_name in required_dirs:
    dir_path = data_dir / dir_name
    if dir_path.exists() and any(dir_path.iterdir()):
        print(f'âœ… {dir_name} å­˜åœ¨ä¸”æœ‰æ•°æ®')
    else:
        print(f'âŒ {dir_name} ç¼ºå¤±æˆ–ä¸ºç©º')
"
```

### 3.2 æ•°æ®é›†åŠ è½½æµ‹è¯•
```bash
# æµ‹è¯•æ•°æ®åŠ è½½
python -c "
from src.datasets.datamodules.coco_datamodule import COCODataModule

# åˆ›å»ºæ•°æ®æ¨¡å—
dm = COCODataModule(data_dir='./test_data/coco128', batch_size=2)

# å‡†å¤‡æ•°æ®
try:
    dm.prepare_data()
    print('âœ… æ•°æ®å‡†å¤‡æˆåŠŸ')
except Exception as e:
    print(f'âŒ æ•°æ®å‡†å¤‡å¤±è´¥: {e}')

# è®¾ç½®æ•°æ®
try:
    dm.setup('fit')
    print('âœ… æ•°æ®è®¾ç½®æˆåŠŸ')
    print(f'è®­ç»ƒæ ·æœ¬: {len(dm.train_dataset)}')
    print(f'éªŒè¯æ ·æœ¬: {len(dm.val_dataset)}')
except Exception as e:
    print(f'âŒ æ•°æ®è®¾ç½®å¤±è´¥: {e}')
"
```

### 3.3 æ•°æ®å¯è§†åŒ–æ£€æŸ¥
```bash
# å¯è§†åŒ–æµ‹è¯•æ•°æ®
python -c "
from src.datasets.datamodules.coco_datamodule import COCODataModule
import matplotlib.pyplot as plt

dm = COCODataModule(data_dir='./test_data/coco128', batch_size=1)
dm.prepare_data()
dm.setup('fit')

# è·å–æ ·æœ¬æ•°æ®
train_loader = dm.train_dataloader()
batch = next(iter(train_loader))
images, targets = batch

print(f'âœ… æ•°æ®æ‰¹æ¬¡å½¢çŠ¶: images={images.shape}, targets={len(targets)}')
print(f'âœ… å›¾åƒèŒƒå›´: [{images.min():.2f}, {images.max():.2f}]')
"
```

## ğŸ” é˜¶æ®µ4: æ¨¡å‹éªŒè¯

### 4.1 æ¨¡å‹å®ä¾‹åŒ–æµ‹è¯•
```bash
# æµ‹è¯•æ¨¡å‹åˆ›å»º
python -c "
from src.models.pytorch.yolov10 import YOLOv10

# åˆ›å»ºæ¨¡å‹
try:
    model = YOLOv10(num_classes=80)
    print('âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ')
    print(f'æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters())}')
except Exception as e:
    print(f'âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}')

# æµ‹è¯•å‰å‘ä¼ æ’­
import torch
x = torch.randn(1, 3, 640, 640)
try:
    outputs = model(x)
    print('âœ… å‰å‘ä¼ æ’­æˆåŠŸ')
    print(f'è¾“å‡ºå½¢çŠ¶: {[out.shape for out in outputs]}')
except Exception as e:
    print(f'âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}')
"
```

### 4.2 æ¨¡å‹é…ç½®éªŒè¯
```bash
# æµ‹è¯•é…ç½®æ–‡ä»¶
python -c "
from omegaconf import OmegaConf
from src.models.pytorch.yolov10 import YOLOv10

# åŠ è½½é…ç½®
cfg = OmegaConf.load('configs/config.yaml')

# åˆ›å»ºæ¨¡å‹
try:
    model = YOLOv10(**cfg.model)
    print('âœ… é…ç½®é©±åŠ¨æ¨¡å‹åˆ›å»ºæˆåŠŸ')
except Exception as e:
    print(f'âŒ é…ç½®é©±åŠ¨æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}')
"
```

### 4.3 æ¨¡å‹ä¿å­˜/åŠ è½½æµ‹è¯•
```bash
# æµ‹è¯•æ¨¡å‹ä¿å­˜å’ŒåŠ è½½
python -c "
import torch
from src.models.pytorch.yolov10 import YOLOv10

model = YOLOv10(num_classes=80)

# ä¿å­˜æ¨¡å‹
torch.save(model.state_dict(), 'test_model.pth')
print('âœ… æ¨¡å‹ä¿å­˜æˆåŠŸ')

# åŠ è½½æ¨¡å‹
model2 = YOLOv10(num_classes=80)
model2.load_state_dict(torch.load('test_model.pth'))
print('âœ… æ¨¡å‹åŠ è½½æˆåŠŸ')

# æ¸…ç†æµ‹è¯•æ–‡ä»¶
import os
os.remove('test_model.pth')
"
```

## ğŸ” é˜¶æ®µ5: è®­ç»ƒæµ‹è¯•

### 5.1 å¿«é€Ÿè®­ç»ƒæµ‹è¯•
```bash
# 1-epochå¿«é€Ÿè®­ç»ƒ
python scripts/train.py \
  model=yolov10n \
  data=coco128 \
  trainer.max_epochs=1 \
  trainer.limit_train_batches=5 \
  trainer.limit_val_batches=5 \
  trainer.fast_dev_run=true

# æ£€æŸ¥è®­ç»ƒç»“æœ
ls -la logs/lightning_logs/version_0/
```

### 5.2 å®Œæ•´è®­ç»ƒæµ‹è¯•
```bash
# 3-epochå®Œæ•´è®­ç»ƒæµ‹è¯•
python scripts/train.py \
  model=yolov10n \
  data=coco128 \
  trainer.max_epochs=3 \
  trainer.accelerator=cpu \
  trainer.devices=1 \
  trainer.log_every_n_steps=1

# ç›‘æ§è®­ç»ƒè¿›åº¦
tail -f logs/lightning_logs/version_0/metrics.csv
```

### 5.3 è®­ç»ƒä¸­æ–­æ¢å¤æµ‹è¯•
```bash
# å¼€å§‹è®­ç»ƒï¼ˆä¼šä¸­æ–­ï¼‰
python scripts/train.py \
  model=yolov10n \
  data=coco128 \
  trainer.max_epochs=5 \
  trainer.limit_train_batches=2 \
  trainer.limit_val_batches=2 &

# è·å–è¿›ç¨‹ID
PID=$!
sleep 10
kill $PID

# æ¢å¤è®­ç»ƒï¼ˆæ£€æŸ¥checkpointï¼‰
python scripts/train.py \
  model=yolov10n \
  data=coco128 \
  trainer.max_epochs=5 \
  trainer.resume_from_checkpoint=logs/lightning_logs/version_0/checkpoints/epoch=0-step=10.ckpt
```

## ğŸ” é˜¶æ®µ6: ç»“æœéªŒè¯

### 6.1 è®­ç»ƒæŒ‡æ ‡æ£€æŸ¥
```bash
# æ£€æŸ¥è®­ç»ƒæŒ‡æ ‡
python -c "
import pandas as pd
import matplotlib.pyplot as plt

# è¯»å–è®­ç»ƒæ—¥å¿—
try:
    metrics = pd.read_csv('logs/lightning_logs/version_0/metrics.csv')
    print('âœ… è®­ç»ƒæ—¥å¿—è¯»å–æˆåŠŸ')
    print('å¯ç”¨æŒ‡æ ‡:', list(metrics.columns))
    
    # æ£€æŸ¥è®­ç»ƒæŸå¤±
    if 'train_loss' in metrics.columns:
        train_loss = metrics['train_loss'].dropna()
        print(f'âœ… è®­ç»ƒæŸå¤±: åˆå§‹={train_loss.iloc[0]:.4f}, æœ€ç»ˆ={train_loss.iloc[-1]:.4f}')
    
    # æ£€æŸ¥éªŒè¯æŸå¤±
    if 'val_loss' in metrics.columns:
        val_loss = metrics['val_loss'].dropna()
        print(f'âœ… éªŒè¯æŸå¤±: åˆå§‹={val_loss.iloc[0]:.4f}, æœ€ç»ˆ={val_loss.iloc[-1]:.4f}')
        
except FileNotFoundError:
    print('âŒ è®­ç»ƒæ—¥å¿—æ–‡ä»¶æœªæ‰¾åˆ°')
except Exception as e:
    print(f'âŒ è®­ç»ƒæ—¥å¿—è¯»å–å¤±è´¥: {e}')
"
```

### 6.2 æ¨¡å‹è¯„ä¼°æµ‹è¯•
```bash
# è¿è¡Œæ¨¡å‹è¯„ä¼°
python scripts/eval.py \
  --config configs/config.yaml \
  --checkpoint logs/lightning_logs/version_0/checkpoints/epoch=2-step=30.ckpt

# æ£€æŸ¥è¯„ä¼°ç»“æœ
ls -la outputs/evaluation/
```

### 6.3 ç»“æœå¯è§†åŒ–
```bash
# å¯è§†åŒ–è®­ç»ƒæ›²çº¿
python -c "
import pandas as pd
import matplotlib.pyplot as plt

try:
    df = pd.read_csv('logs/lightning_logs/version_0/metrics.csv')
    
    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    plt.figure(figsize=(12, 4))
    
    # è®­ç»ƒæŸå¤±
    if 'train_loss' in df.columns:
        train_loss = df['train_loss'].dropna()
        plt.subplot(1, 2, 1)
        plt.plot(train_loss)
        plt.title('Training Loss')
        plt.xlabel('Step')
        plt.ylabel('Loss')
    
    # éªŒè¯æŸå¤±
    if 'val_loss' in df.columns:
        val_loss = df['val_loss'].dropna()
        plt.subplot(1, 2, 2)
        plt.plot(val_loss)
        plt.title('Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
    
    plt.tight_layout()
    plt.savefig('outputs/training_curves.png', dpi=150, bbox_inches='tight')
    print('âœ… è®­ç»ƒæ›²çº¿å·²ä¿å­˜')
    
except Exception as e:
    print(f'âŒ å¯è§†åŒ–å¤±è´¥: {e}')
"
```

## ğŸ“‹ è°ƒè¯•æ£€æŸ¥æ¸…å•

### ç¯å¢ƒæ£€æŸ¥
- [ ] Pythonç‰ˆæœ¬æ­£ç¡®ï¼ˆ3.9-3.10ï¼‰
- [ ] æ‰€æœ‰ä¾èµ–å®‰è£…æˆåŠŸ
- [ ] é¡¹ç›®è·¯å¾„é…ç½®æ­£ç¡®
- [ ] å¿…éœ€æ–‡ä»¶å­˜åœ¨

### å¯¼å…¥æµ‹è¯•
- [ ] åŸºç¡€æ¨¡å—å¯¼å…¥æˆåŠŸ
- [ ] æ¨¡å‹ç±»å¯¼å…¥æˆåŠŸ
- [ ] æ•°æ®é›†ç±»å¯¼å…¥æˆåŠŸ
- [ ] å·¥å…·å‡½æ•°å¯¼å…¥æˆåŠŸ

### æ•°æ®é›†éªŒè¯
- [ ] æ•°æ®é›†ä¸‹è½½æˆåŠŸ
- [ ] æ•°æ®åŠ è½½æ­£å¸¸
- [ ] æ•°æ®é¢„å¤„ç†æ­£ç¡®
- [ ] æ•°æ®å¯è§†åŒ–æ­£å¸¸

### æ¨¡å‹éªŒè¯
- [ ] æ¨¡å‹åˆ›å»ºæˆåŠŸ
- [ ] å‰å‘ä¼ æ’­æ­£å¸¸
- [ ] æ¨¡å‹ä¿å­˜/åŠ è½½æ­£å¸¸
- [ ] é…ç½®é©±åŠ¨æ­£ç¡®

### è®­ç»ƒæµ‹è¯•
- [ ] 1-epochè®­ç»ƒæˆåŠŸ
- [ ] è®­ç»ƒæ—¥å¿—ç”Ÿæˆ
- [ ] checkpointä¿å­˜
- [ ] ä¸­æ–­æ¢å¤æµ‹è¯•

### ç»“æœéªŒè¯
- [ ] è®­ç»ƒæŒ‡æ ‡æ­£å¸¸
- [ ] æ¨¡å‹è¯„ä¼°æˆåŠŸ
- [ ] ç»“æœå¯è§†åŒ–æ­£å¸¸
- [ ] æ€§èƒ½ç¬¦åˆé¢„æœŸ

## ğŸ¯ è°ƒè¯•å‘½ä»¤æ±‡æ€»

### ä¸€é”®è°ƒè¯•è„šæœ¬
```bash
#!/bin/bash
# debug_all.sh - ä¸€é”®è¿è¡Œæ‰€æœ‰è°ƒè¯•æµ‹è¯•

echo "=== å¼€å§‹ä»£ç éªŒè¯ ==="

# ç¯å¢ƒæ£€æŸ¥
echo "1. ç¯å¢ƒæ£€æŸ¥..."
python --version
python -c "import torch, paddle; print('âœ… æ¡†æ¶å¯¼å…¥æˆåŠŸ')"

# å¯¼å…¥æµ‹è¯•
echo "2. å¯¼å…¥æµ‹è¯•..."
python -c "from src.models.pytorch.yolov10 import YOLOv10; print('âœ… PyTorchæ¨¡å‹')"
python -c "from src.datasets.coco_detection import COCODetection; print('âœ… æ•°æ®é›†')"

# æ•°æ®é›†éªŒè¯
echo "3. æ•°æ®é›†éªŒè¯..."
python scripts/download.py --dataset coco128 --data_dir ./test_data

# å¿«é€Ÿè®­ç»ƒæµ‹è¯•
echo "4. è®­ç»ƒæµ‹è¯•..."
python scripts/train.py model=yolov10n data=coco128 trainer.max_epochs=1 trainer.fast_dev_run=true

echo "=== è°ƒè¯•å®Œæˆ ==="
```

### è°ƒè¯•å·¥å…·

```bash
# å®‰è£…è°ƒè¯•å·¥å…·
pip install ipdb rich tensorboard

# äº¤äº’å¼è°ƒè¯•
python -m ipdb scripts/train.py model=yolov10n data=coco128 trainer.fast_dev_run=true

# å®æ—¶ç›‘æ§
python -m tensorboard.main --logdir logs/lightning_logs/ --port 6006
```

## ğŸš¨ å¸¸è§é”™è¯¯åŠè§£å†³

### é”™è¯¯1: å¯¼å…¥å¤±è´¥
```
ImportError: No module named 'src.models'
è§£å†³: export PYTHONPATH="${PYTHONPATH}:$(pwd)"
```

### é”™è¯¯2: æ•°æ®é›†ä¸‹è½½å¤±è´¥
```
ConnectionError: Failed to download
è§£å†³: æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–ä½¿ç”¨ä»£ç†
```

### é”™è¯¯3: å†…å­˜ä¸è¶³
```
RuntimeError: [enforce fail at CPUAllocator.cpp] alloc
è§£å†³: å‡å°batch_sizeæˆ–ä½¿ç”¨CPUä¼˜åŒ–è®¾ç½®
```

### é”™è¯¯4: é…ç½®é”™è¯¯
```
ValidationError: Invalid config
è§£å†³: æ£€æŸ¥YAMLæ ¼å¼ï¼ŒéªŒè¯é…ç½®å‚æ•°
```

## ğŸ“Š æ€§èƒ½åŸºå‡†

### CPUè®­ç»ƒåŸºå‡†
| æ•°æ®é›† | Batch Size | Epochs | è®­ç»ƒæ—¶é—´ | å†…å­˜ä½¿ç”¨ |
|--------|------------|--------|----------|----------|
| CIFAR-10 | 32 | 1 | ~45ç§’ | ~1GB |
| COCO128 | 16 | 1 | ~5åˆ†é’Ÿ | ~3GB |
| ImageNet | 32 | 1 | ~45åˆ†é’Ÿ | ~2GB |

## ğŸ¯ è§„èŒƒï¼ˆSpecï¼‰éªŒè¯ä¸è§„æ ¼è¿½è¸ª

### ğŸ“‹ ä»INITIAL.mdè·å–éªŒè¯æ ‡å‡†

#### **è§„æ ¼éªŒè¯çŸ©é˜µ**

| INITIAL.mdè§„æ ¼å­—æ®µ | éªŒè¯æ–¹æ³• | æ£€æŸ¥è„šæœ¬ | é€šè¿‡æ ‡å‡† |
|-------------------|----------|----------|----------|
| **project_spec.name** | é¡¹ç›®åç§°æ£€æŸ¥ | `echo $PROJECT_NAME` | ä¸INITIAL.mdä¸€è‡´ |
| **algorithm_spec.model_architecture** | æ¨¡å‹åˆ›å»ºæµ‹è¯• | `python -c "from src.models..."` | æ¨¡å‹æˆåŠŸå®ä¾‹åŒ– |
| **performance_targets.training.epoch_time** | è®­ç»ƒæ—¶é—´éªŒè¯ | `time python scripts/train.py...` | ç¬¦åˆæ—¶é—´é¢„æœŸ |
| **performance_targets.inference.latency** | æ¨ç†é€Ÿåº¦æµ‹è¯• | `python scripts/benchmark.py` | è¾¾åˆ°å»¶è¿Ÿè¦æ±‚ |

#### **è§„æ ¼ç»§æ‰¿éªŒè¯**

```bash
# éªŒè¯CREATE.mdå†³ç­–åœ¨INITIAL.mdä¸­çš„ç»§æ‰¿
python -c "
from pathlib import Path
import yaml

# æ£€æŸ¥è§„æ ¼æ–‡æ¡£å­˜åœ¨
spec_files = [
    '../CREATE.md',
    '../INITIAL.md',
    '../ML.md',
    '../TASK.md'
]

for file in spec_files:
    if Path(file).exists():
        print(f'âœ… {file} å­˜åœ¨')
    else:
        print(f'âŒ {file} ç¼ºå¤±')

# éªŒè¯è§„æ ¼ä¸€è‡´æ€§
print('\n=== è§„æ ¼ä¸€è‡´æ€§æ£€æŸ¥ ===')
try:
    # è¯»å–INITIAL.mdä¸­çš„è§„æ ¼
    with open('../INITIAL.md', 'r') as f:
        initial_content = f.read()
    
    # æ£€æŸ¥å…³é”®è§„æ ¼å­—æ®µ
    required_specs = [
        'project_spec.name',
        'algorithm_spec.model_architecture', 
        'training_spec.epochs',
        'performance_targets.inference.latency'
    ]
    
    for spec in required_specs:
        if spec in initial_content:
            print(f'âœ… {spec} å·²å®šä¹‰')
        else:
            print(f'âŒ {spec} ç¼ºå¤±')
            
except Exception as e:
    print(f'âŒ è§„æ ¼è¯»å–å¤±è´¥: {e}')
"
```

### ğŸ” è§„æ ¼é©±åŠ¨éªŒè¯æµç¨‹

#### **éªŒè¯CREATE.mdæŠ€æœ¯é€‰å‹**

```bash
# 1. éªŒè¯æ¡†æ¶é€‰æ‹©ï¼ˆCREATE.md â†’ ML.md â†’ å®ç°ï¼‰
python -c "
import torch
import paddle

# æ£€æŸ¥PyTorchç‰ˆæœ¬ï¼ˆCREATE.mdå†³ç­– â†’ ML.mdç‰ˆæœ¬çŸ©é˜µï¼‰
expected_pytorch = '2.6.0'
actual_pytorch = torch.__version__
if expected_pytorch in actual_pytorch:
    print(f'âœ… PyTorchç‰ˆæœ¬ç¬¦åˆCREATE.mdå†³ç­–: {actual_pytorch}')
else:
    print(f'âŒ PyTorchç‰ˆæœ¬ä¸ç¬¦: æœŸæœ›{expected_pytorch}, å®é™…{actual_pytorch}')

# æ£€æŸ¥PaddlePaddleç‰ˆæœ¬
expected_paddle = '2.6.0'
actual_paddle = paddle.__version__
if expected_paddle in actual_paddle:
    print(f'âœ… PaddlePaddleç‰ˆæœ¬ç¬¦åˆCREATE.mdå†³ç­–: {actual_paddle}')
else:
    print(f'âŒ PaddlePaddleç‰ˆæœ¬ä¸ç¬¦: æœŸæœ›{expected_paddle}, å®é™…{actual_paddle}')
"
```

#### **éªŒè¯INITIAL.mdæ€§èƒ½ç›®æ ‡**

```bash
# 2. éªŒè¯æ€§èƒ½åŸºå‡†ï¼ˆINITIAL.md â†’ å®é™…è¿è¡Œï¼‰
python -c "
import time
import torch
from src.models.pytorch.yolov10 import YOLOv10

# æµ‹è¯•æ¨ç†å»¶è¿Ÿ
model = YOLOv10(num_classes=80)
model.eval()
dummy_input = torch.randn(1, 3, 640, 640)

# é¢„çƒ­
for _ in range(5):
    _ = model(dummy_input)

# æ­£å¼æµ‹è¯•
start_time = time.time()
with torch.no_grad():
    for _ in range(100):
        _ = model(dummy_input)
end_time = time.time()

avg_latency = (end_time - start_time) / 100 * 1000  # ms
print(f'æ¨ç†å»¶è¿Ÿ: {avg_latency:.2f}ms')

# ä¸INITIAL.mdè§„æ ¼å¯¹æ¯”
expected_latency = 200  # ms
if avg_latency <= expected_latency:
    print(f'âœ… å»¶è¿Ÿç¬¦åˆINITIAL.mdè§„æ ¼: â‰¤{expected_latency}ms')
else:
    print(f'âŒ å»¶è¿Ÿè¶…æ ‡: æœŸæœ›â‰¤{expected_latency}ms, å®é™…{avg_latency:.2f}ms')
"
```

#### **éªŒè¯éƒ¨ç½²è§„æ ¼åˆè§„æ€§**

```bash
# 3. éªŒè¯éƒ¨ç½²è§„æ ¼ï¼ˆINITIAL.md â†’ DOCKER_CONFIG.mdï¼‰
python -c "
import subprocess
import sys

# æ£€æŸ¥Dockerç¯å¢ƒï¼ˆINITIAL.mdéƒ¨ç½²è§„æ ¼ï¼‰
try:
    result = subprocess.run(['docker', '--version'], 
                          capture_output=True, text=True)
    if result.returncode == 0:
        print(f'âœ… Dockerç¯å¢ƒç¬¦åˆINITIAL.mdè§„æ ¼: {result.stdout.strip()}')
    else:
        print('âŒ Dockerç¯å¢ƒæ£€æŸ¥å¤±è´¥')
except:
    print('âŒ Dockeræœªå®‰è£…')

# æ£€æŸ¥GPUå¯ç”¨æ€§ï¼ˆINITIAL.mdç¡¬ä»¶è¦æ±‚ï¼‰
import torch
gpu_available = torch.cuda.is_available()
if gpu_available:
    gpu_count = torch.cuda.device_count()
    gpu_name = torch.cuda.get_device_name(0)
    print(f'âœ… GPUç¬¦åˆINITIAL.mdè§„æ ¼: {gpu_count}ä¸ªGPU ({gpu_name})')
else:
    print('âš ï¸ å½“å‰ä¸ºCPUç¯å¢ƒï¼Œéœ€éªŒè¯GPUç¯å¢ƒé…ç½®')
"
```

### ğŸ“Š è§„æ ¼è¿½è¸ªæŠ¥å‘Š

#### **ç”Ÿæˆè§„æ ¼éªŒè¯æŠ¥å‘Š**

```bash
# åˆ›å»ºè§„æ ¼éªŒè¯æŠ¥å‘Š
python -c "
import datetime
import json

report = {
    'timestamp': str(datetime.datetime.now()),
    'spec_source': 'INITIAL.md',
    'validation_items': {
        'project_name': 'å¾…éªŒè¯',
        'framework_version': 'å¾…éªŒè¯',
        'model_architecture': 'å¾…éªŒè¯',
        'performance_target': 'å¾…éªŒè¯',
        'deployment_spec': 'å¾…éªŒè¯'
    },
    'status': 'spec_verification_in_progress'
}

print('=== è§„æ ¼éªŒè¯æŠ¥å‘Š ===')
print(json.dumps(report, indent=2, ensure_ascii=False))

# ä¿å­˜æŠ¥å‘Š
with open('outputs/spec_validation_report.json', 'w') as f:
    json.dump(report, f, indent=2, ensure_ascii=False)
print('âœ… è§„æ ¼éªŒè¯æŠ¥å‘Šå·²ç”Ÿæˆ')
"
```

### ğŸ¯ è§„æ ¼åˆè§„æ£€æŸ¥æ¸…å•

#### **CREATE.mdå†³ç­–éªŒè¯**
- [ ] é¡¹ç›®åç§°ä¸CREATE.mdè§„åˆ’ä¸€è‡´
- [ ] æŠ€æœ¯æ ˆé€‰æ‹©ç¬¦åˆCREATE.mdå†³ç­–
- [ ] èµ„æºéœ€æ±‚è¯„ä¼°ä¸CREATE.mdåŒ¹é…
- [ ] æ—¶é—´è§„åˆ’æ¡†æ¶å·²æ­£ç¡®å®æ–½

#### **INITIAL.mdè§„æ ¼éªŒè¯**
- [ ] ç®—æ³•åŠŸèƒ½è§„æ ¼å·²å®ç°
- [ ] æ€§èƒ½ç›®æ ‡å·²è¾¾åˆ°
- [ ] ç›®å½•ç»“æ„ç¬¦åˆè§„æ ¼
- [ ] è®­ç»ƒè§„æ ¼å‚æ•°æ­£ç¡®é…ç½®
- [ ] éƒ¨ç½²è§„æ ¼å·²éªŒè¯

#### **è§„æ ¼è¿½è¸ªé“¾å»ºç«‹**
- [ ] CREATE.md â†’ INITIAL.md â†’ å®ç°ä»£ç  æœ‰å®Œæ•´è¿½è¸ª
- [ ] æ¯ä¸ªéªŒè¯æ­¥éª¤éƒ½æœ‰è§„æ ¼ä¾æ®
- [ ] æ‰€æœ‰åå·®éƒ½æœ‰è®°å½•å’Œè§£é‡Š
- [ ] è§„æ ¼éªŒè¯æŠ¥å‘Šå·²ç”Ÿæˆ

## ğŸ¯ ä¸‹ä¸€æ­¥

å®Œæˆä»£ç éªŒè¯å’Œè§„èŒƒéªŒè¯åï¼š
1. **è§„æ ¼åˆè§„ç¡®è®¤**ï¼šç¡®ä¿æ‰€æœ‰éªŒè¯ç»“æœç¬¦åˆINITIAL.mdè§„æ ¼
2. **æŸ¥çœ‹ [DOCKER_CONFIG.md](./DOCKER_CONFIG.md)**ï¼šé…ç½®GPUç¯å¢ƒï¼ŒéªŒè¯éƒ¨ç½²è§„æ ¼
3. **è¿è¡Œ [DEPLOY.md](./DEPLOY.md)**ï¼šè¿›è¡Œç”Ÿäº§éƒ¨ç½²ï¼ŒéªŒè¯æœ€ç»ˆè§„æ ¼åˆè§„æ€§
4. **æ›´æ–° [PROJECT_BUILD_LOG.md](./PROJECT_BUILD_LOG.md)**ï¼šè®°å½•è§„æ ¼éªŒè¯ç»“æœ

**è§„èŒƒï¼ˆSpecï¼‰é©±åŠ¨éªŒè¯æµç¨‹**ï¼š
- é¡¹ç›®åˆ›å»ºå‰ï¼šå®ŒæˆCREATE.md â†’ å†™å…¥INITIAL.md â†’ å»ºç«‹è§„æ ¼è¿½è¸ªé“¾
- é¡¹ç›®éªŒè¯ä¸­ï¼šDEBUGé˜¶æ®µç¡®ä¿ä»£ç è´¨é‡ â†’ éªŒè¯è§„æ ¼åˆè§„æ€§ â†’ DOCKERé˜¶æ®µéªŒè¯æ€§èƒ½è§„æ ¼

---
**éªŒè¯æ—¶é—´**: ~10åˆ†é’Ÿ | **è°ƒè¯•æ—¶é—´**: ~30åˆ†é’Ÿ | **æ€»è®¡**: ~40åˆ†é’Ÿ