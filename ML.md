# ğŸ¤– æŠ€æœ¯é€‰å‹è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“è§„èŒƒï¼ˆTechnical Selection Agentic-ai-coder Specificationï¼‰

> **æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“è¡Œä¸ºå‡†åˆ™** - åŸºäºé‡åŒ–å†³ç­–çŸ©é˜µçš„æ¡†æ¶ç‰ˆæœ¬é€‰æ‹©ä¸ç¡¬ä»¶éœ€æ±‚è¯„ä¼°ï¼Œç¡®ä¿æŠ€æœ¯é€‰å‹æœ‰ç†æœ‰æ®ã€‚

## ğŸ¯ æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“è§’è‰²å®šä¹‰

### ğŸ“‹ æ™ºèƒ½ä½“èŒè´£è¾¹ç•Œ
- **è§’è‰²å®šä½**: æŠ€æœ¯é€‰å‹ä¸ç¡¬ä»¶éœ€æ±‚è¯„ä¼°çš„è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“
- **æ ¸å¿ƒèŒè´£**: åŸºäºCREATE.mdéœ€æ±‚è¿›è¡Œæ¡†æ¶ç‰ˆæœ¬é€‰æ‹©ä¸ç¡¬ä»¶é…ç½®
- **è¾“å…¥è§„èŒƒ**: CREATE.mdéœ€æ±‚æè¿° + PLANNING.mdæŠ€æœ¯å†³ç­–
- **è¾“å‡ºè§„èŒƒ**: æ¡†æ¶ç‰ˆæœ¬çŸ©é˜µ + ç¡¬ä»¶éœ€æ±‚è¯„ä¼° + æ€§èƒ½åŸºå‡†
- **éªŒè¯æ ‡å‡†**: é‡åŒ–å†³ç­–çŸ©é˜µè¯„åˆ†â‰¥3.5åˆ†ï¼ŒGPUå†…å­˜ç²¾ç¡®è®¡ç®—

### ğŸ”„ æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“åä½œæµç¨‹
```mermaid
graph TD
    subgraph æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“è¾“å…¥
        CREATE[CREATE.mdéœ€æ±‚] --> TECH[æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“<br/>é€‰å‹å†³ç­–]
        PLAN[PLANNING.mdå†³ç­–] --> TECH
    end
    
    subgraph æŠ€æœ¯è¯„ä¼°
        TECH -->|è¯„ä¼°| FRAME[æ¡†æ¶é€‰æ‹©<br/>ç‰ˆæœ¬çŸ©é˜µ]
        TECH -->|è®¡ç®—| HARDWARE[ç¡¬ä»¶éœ€æ±‚<br/>ç²¾ç¡®è®¡ç®—]
        TECH -->|éªŒè¯| BENCHMARK[æ€§èƒ½åŸºå‡†<br/>éªŒè¯æ ‡å‡†]
        TECH -->|è¾“å‡º| INITIAL[INITIAL.md<br/>æŠ€æœ¯è§„æ ¼]
    end
    
    subgraph è¾“å‡ºè§„èŒƒ
        FRAME -->|ç”Ÿæˆ| SPEC[æŠ€æœ¯è§„æ ¼<br/>æ¡†æ¶ç‰ˆæœ¬]
        HARDWARE -->|ç”Ÿæˆ| SPEC
        BENCHMARK -->|ç”Ÿæˆ| SPEC
    end
    
    style TECH fill:#90EE90,stroke:#333
    style CREATE fill:#FFD700,stroke:#333
    style SPEC fill:#87CEEB,stroke:#333
```

## ğŸ¯ æŠ€æœ¯é€‰å‹å†³ç­–çŸ©é˜µ

### ğŸ“Š æ¡†æ¶ç‰ˆæœ¬ç²¾ç¡®è§„èŒƒ
| é˜¶æ®µ | æ™ºèƒ½ä½“èŒè´£ | PyTorchç‰ˆæœ¬ | PaddlePaddleç‰ˆæœ¬ | CUDAç‰ˆæœ¬ | è§„èŒƒå¼•ç”¨ä½ç½® | éªŒè¯æ ‡å‡† |
|------|------------|-------------|------------------|----------|--------------|----------|
| **VENVè°ƒè¯•** | æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“CPUéªŒè¯ | 2.6.0+cpu | 2.6.0+cpu | N/A | ML.mdç¬¬1ç«  | CPUç¯å¢ƒéªŒè¯ |
| **DOCKERéƒ¨ç½²** | æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“GPUä¼˜åŒ– | 2.6.0+cu126 | 2.6.0+gpu | 12.6 | ML.mdç¬¬2ç«  | GPUåˆ©ç”¨ç‡>90% |

### ğŸ¯ æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“å†³ç­–æ¡†æ¶

#### 1. æ¡†æ¶é€‰æ‹©çŸ©é˜µï¼ˆCREATE.mdå¼•ç”¨ï¼‰
**è§„èŒƒå¼•ç”¨**: åŸºäºCREATE.mdç¬¬6ç« "æŠ€æœ¯é€‰å‹å†³ç­–"
```yaml
æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“æ¡†æ¶é€‰æ‹©è§„èŒƒ:
  è¾“å…¥æ¥æº: "CREATE.mdéœ€æ±‚è§„æ ¼+PLANNING.mdæŠ€æœ¯å†³ç­–"
  å†³ç­–çŸ©é˜µ: "é‡åŒ–è¯„åˆ†ç³»ç»Ÿ"
  è¯„ä¼°ç»´åº¦: ["å›¢é˜Ÿç†Ÿæ‚‰åº¦", "éƒ¨ç½²ä¾¿åˆ©æ€§", "æ€§èƒ½ä¼˜åŒ–", "ç¤¾åŒºæ”¯æŒ"]
  æƒé‡åˆ†é…: [0.30, 0.25, 0.25, 0.20]
  é€‰æ‹©é˜ˆå€¼: "â‰¥3.5åˆ†æ¨èé‡‡ç”¨"
  éªŒè¯æ ‡å‡†: "ML.mdæ€§èƒ½åŸºå‡†æµ‹è¯•"
```

**æ¡†æ¶å†³ç­–æ ‡å‡†**:
| è¯„ä¼°ç»´åº¦ | æƒé‡ | PyTorchè¯„åˆ† | Paddleè¯„åˆ† | å†³ç­–ä¾æ® |
|----------|------|-------------|------------|----------|
| **å›¢é˜Ÿç†Ÿæ‚‰åº¦** | 30% | â˜…â˜…â˜…â˜…â˜† 4.0 | â˜…â˜…â˜…â˜†â˜† 3.0 | CREATE.mdå›¢é˜ŸèƒŒæ™¯ |
| **éƒ¨ç½²ä¾¿åˆ©æ€§** | 25% | â˜…â˜…â˜…â˜†â˜† 3.5 | â˜…â˜…â˜…â˜…â˜† 4.2 | DOCKER_CONFIG.mdéªŒè¯ |
| **æ€§èƒ½ä¼˜åŒ–** | 25% | â˜…â˜…â˜…â˜…â˜† 4.0 | â˜…â˜…â˜…â˜…â˜† 4.0 | ML.mdæ€§èƒ½åŸºå‡† |
| **ç¤¾åŒºæ”¯æŒ** | 20% | â˜…â˜…â˜…â˜…â˜… 5.0 | â˜…â˜…â˜…â˜†â˜† 3.5 | é—®é¢˜è§£å†³æ•ˆç‡ |
| **ç»¼åˆå¾—åˆ†** | 100% | **4.1åˆ†** | **3.6åˆ†** | **æ¨èPyTorch** |

#### 2. ç¡¬ä»¶éœ€æ±‚è®¡ç®—ï¼ˆPLANNING.mdå¼•ç”¨ï¼‰
**è§„èŒƒå¼•ç”¨**: ä¾æ®PLANNING.mdç¬¬3ç« "èµ„æºè¯„ä¼°ç­–ç•¥"
```yaml
æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“ç¡¬ä»¶è®¡ç®—è§„èŒƒ:
  è¾“å…¥æ¥æº: "PLANNING.mdèµ„æºéœ€æ±‚è§„åˆ’"
  è®¡ç®—å…¬å¼: "GPUå†…å­˜ = æ¨¡å‹å‚æ•° + æ¿€æ´»å€¼ + ä¼˜åŒ–å™¨çŠ¶æ€ + æ•°æ®ç¼“å­˜"
  å®‰å…¨ä½™é‡: "50%é¢å¤–å†…å­˜é¢„ç•™"
  éªŒè¯æ–¹æ³•: "ML.mdå®é™…æµ‹è¯•æ•°æ®"
```

**ç¡¬ä»¶éœ€æ±‚ç²¾ç¡®è®¡ç®—**:
```python
# æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“å†…å­˜è®¡ç®—æ¨¡æ¿
def calculate_gpu_memory(model_name, batch_size):
    """
    åŸºäºML.mdç¬¬2ç« çš„ç²¾ç¡®è®¡ç®—å…¬å¼
    """
    memory_map = {
        'resnet18': {
            'model_params': 11.7,  # MB
            'activation_per_batch': 0.5 * batch_size,  # MB
            'optimizer_state': 23.4,  # MB (å‚æ•°*2)
            'data_cache': 500,  # MB
        },
        'yolov10n': {
            'model_params': 5.0,  # MB
            'activation_per_batch': 2.0 * batch_size,  # MB
            'optimizer_state': 10.0,  # MB
            'data_cache': 1000,  # MB
        }
    }
    return memory_map[model_name]

# æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“æ¨èé…ç½®
configurations = {
    'CIFAR-10åˆ†ç±»': {
        'model': 'resnet18',
        'batch_size': 32,
        'gpu_memory': '8GB RTX 3060',
        'training_time': '30åˆ†é’Ÿ/epoch',
        'reference': 'ML.mdç¬¬3ç« æ€§èƒ½åŸºå‡†'
    },
    'ImageNetåˆ†ç±»': {
        'model': 'resnet50', 
        'batch_size': 64,
        'gpu_memory': '24GB RTX 4090',
        'training_time': '8åˆ†é’Ÿ/epoch',
        'reference': 'ML.mdç¬¬3ç« æ€§èƒ½åŸºå‡†'
    }
}
```

#### 3. æ€§èƒ½åŸºå‡†éªŒè¯ï¼ˆML.mdå¼•ç”¨ï¼‰
**è§„èŒƒå¼•ç”¨**: ä½¿ç”¨ML.mdç¬¬3ç« "æ€§èƒ½åŸºå‡†éªŒè¯"
```yaml
æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“æ€§èƒ½éªŒè¯è§„èŒƒ:
  åŸºå‡†æµ‹è¯•: "ResNet-50 on ImageNet"
  æµ‹è¯•ç¯å¢ƒ: "RTX 3060 8GB"
  éªŒè¯æŒ‡æ ‡: ["è®­ç»ƒæ—¶é—´/epoch", "GPUåˆ©ç”¨ç‡", "å†…å­˜ä½¿ç”¨"]
  éªŒæ”¶æ ‡å‡†: "GPUåˆ©ç”¨ç‡>90%, å†…å­˜ä½¿ç”¨<80%"
```

## ğŸ“Š æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“éªŒè¯çŸ©é˜µ

### ğŸ“‹ æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“éªŒæ”¶æ¸…å•
æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“å®Œæˆé€‰å‹åï¼Œå¿…é¡»éªŒè¯ï¼š
- [ ] æ¡†æ¶é€‰æ‹©æœ‰CREATE.mdç¬¬6ç« çš„é‡åŒ–è¯„åˆ†ä¾æ®
- [ ] ç¡¬ä»¶éœ€æ±‚ç»è¿‡ML.mdç¬¬2ç« çš„ç²¾ç¡®è®¡ç®—
- [ ] æ€§èƒ½åŸºå‡†ç¬¦åˆML.mdç¬¬3ç« çš„éªŒè¯æ ‡å‡†
- [ ] ç‰ˆæœ¬å…¼å®¹æ€§é€šè¿‡ML.mdç¬¬5ç« çš„æµ‹è¯•éªŒè¯

### ğŸ“Š æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“æ€§èƒ½åŸºå‡†
| éªŒè¯ç»´åº¦ | æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“æ ‡å‡† | ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯” |
|----------|--------------|--------------|
| **å†³ç­–æ—¶é—´** | 10åˆ†é’Ÿé‡åŒ–åˆ†æ | æ•°å¤©ç»éªŒå†³ç­– |
| **è®¡ç®—ç²¾åº¦** | GPUå†…å­˜ç²¾ç¡®åˆ°MB | ç²—ç•¥ä¼°ç®— |
| **æ€§èƒ½é¢„æµ‹** | åŸºäºML.mdå®é™…æ•°æ® | ç†è®ºæ¨æµ‹ |
| **æˆæœ¬è¯„ä¼°** | ç¡¬ä»¶éœ€æ±‚é‡åŒ–è®¡ç®— | ç»éªŒåˆ¤æ–­ |

## ğŸ¯ æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“å¿«é€Ÿå¼€å§‹

### ç«‹å³æ‰§è¡Œæ­¥éª¤
1. **æ‰“å¼€CREATE.mdç¬¬6ç« ** - å¯åŠ¨æŠ€æœ¯é€‰å‹å†³ç­–çŸ©é˜µ
2. **è¿è¡ŒML.mdå†…å­˜è®¡ç®—** - ç²¾ç¡®è®¡ç®—GPUéœ€æ±‚
3. **å‚è€ƒML.mdæ€§èƒ½åŸºå‡†** - éªŒè¯æŠ€æœ¯å¯è¡Œæ€§
4. **ç”ŸæˆæŠ€æœ¯è§„æ ¼** - æ¡†æ¶ç‰ˆæœ¬+ç¡¬ä»¶é…ç½®æ ‡å‡†åŒ–è¾“å‡º

### æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“æˆåŠŸæ ‡å‡†
**æ ¸å¿ƒè®°å¿†ç‚¹**: "10åˆ†é’Ÿçš„æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“é‡åŒ–åˆ†æï¼Œèƒœè¿‡æ•°å¤©çš„ç»éªŒå†³ç­–ï¼"

## ğŸ“Š æ¡†æ¶ç‰ˆæœ¬çŸ©é˜µä¸ä¸¤é˜¶æ®µç¯å¢ƒé…ç½®

### ç¯å¢ƒé…ç½®æ€»è§ˆ

| é˜¶æ®µ | æ™ºèƒ½ä½“èŒè´£ | PyTorchç‰ˆæœ¬ | PaddlePaddleç‰ˆæœ¬ | CUDAç‰ˆæœ¬ | è§„èŒƒå¼•ç”¨ä½ç½® | éªŒè¯æ ‡å‡† |
|------|------------|-------------|------------------|----------|--------------|----------|
| **VENVè°ƒè¯•** | æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“CPUéªŒè¯ | 2.6.0+cpu | 2.6.0+cpu | N/A | ML.mdç¬¬1ç«  | CPUç¯å¢ƒéªŒè¯ |
| **DOCKERéƒ¨ç½²** | æŠ€æœ¯è‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“GPUä¼˜åŒ– | 2.6.0+cu126 | 2.6.0+gpu | 12.6 | ML.mdç¬¬2ç«  | GPUåˆ©ç”¨ç‡>90% |

### VENVè°ƒè¯•ç¯å¢ƒï¼ˆCPU-onlyï¼‰

#### PyTorch CPUç¯å¢ƒ
```bash
# åˆ›å»ºè°ƒè¯•ç¯å¢ƒ
conda create -n ml-debug python=3.10
conda activate ml-debug

# PyTorch CPUç‰ˆæœ¬
pip install torch==2.6.0+cpu torchvision==0.15.0+cpu torchaudio==2.0.0+cpu \
  --index-url https://download.pytorch.org/whl/cpu

# éªŒè¯å®‰è£…
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
```

#### PaddlePaddle CPUç¯å¢ƒ
```bash
# PaddlePaddle CPUç‰ˆæœ¬
pip install paddlepaddle==2.6.0 -f https://www.paddlepaddle.org.cn/whl/linux/cpu-mkl/avx/stable.html

# éªŒè¯å®‰è£…
python -c "import paddle; print(f'PaddlePaddle: {paddle.__version__}, GPU: {paddle.is_compiled_with_cuda()}')"
```

#### é€šç”¨ä¾èµ–ï¼ˆCPUç¯å¢ƒï¼‰
```bash
pip install pytorch-lightning==2.0.0 omegaconf==2.3.0 \
  torchmetrics==0.11.0 scikit-learn==1.3.0 \
  matplotlib==3.7.0 seaborn==0.12.0 \
  tensorboard==2.13.0 wandb==0.15.0
```

### DOCKERéƒ¨ç½²ç¯å¢ƒï¼ˆGPUåŠ é€Ÿï¼‰

#### åŸºç¡€é•œåƒé€‰æ‹©

| æ¡†æ¶ | å®˜æ–¹é•œåƒ | æ ‡ç­¾ | å¤§å° |
|------|----------|------|------|
| PyTorch | pytorch/pytorch | 2.6.0-cuda12.6-cudnn9-devel | ~8GB |
| PaddlePaddle | paddlepaddle/paddle | 2.6.0-gpu-cuda12.6-cudnn9 | ~6GB |

#### Dockerfileæ¨¡æ¿

**PyTorch GPUç‰ˆæœ¬**
```dockerfile
FROM pytorch/pytorch:2.6.0-cuda12.6-cudnn9-devel

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    git wget unzip \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir \
    pytorch-lightning==2.0.0 \
    omegaconf==2.3.0 \
    torchmetrics==0.11.0 \
    wandb==0.15.0 \
    tensorboard==2.13.0

WORKDIR /workspace
COPY . .
CMD ["python", "scripts/train.py"]
```

**PaddlePaddle GPUç‰ˆæœ¬**
```dockerfile
FROM paddlepaddle/paddle:2.6.0-gpu-cuda12.6-cudnn9

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir \
    omegaconf==2.3.0 \
    scikit-learn==1.3.0 \
    matplotlib==3.7.0 \
    seaborn==0.12.0 \
    wandb==0.15.0 \
    tensorboard==2.13.0

WORKDIR /workspace
COPY . .
CMD ["python", "scripts/train.py"]
```

### ç‰ˆæœ¬å…¼å®¹æ€§çŸ©é˜µ

#### Pythonç‰ˆæœ¬æ”¯æŒ
| Python | PyTorch | PaddlePaddle | çŠ¶æ€ |
|--------|---------|--------------|------|
| 3.8 | âœ… | âœ… | ç¨³å®š |
| 3.9 | âœ… | âœ… | æ¨è |
| 3.10 | âœ… | âœ… | æ¨è |
| 3.11 | âš ï¸ | âš ï¸ | æµ‹è¯•ç‰ˆ |

#### CUDAç‰ˆæœ¬å…¼å®¹æ€§
| CUDAç‰ˆæœ¬ | PyTorchç‰ˆæœ¬ | PaddlePaddleç‰ˆæœ¬ | é©±åŠ¨è¦æ±‚ |
|----------|-------------|------------------|----------|
| 11.8 | 2.0.0+ | 2.4.0+ | â‰¥ 515.00 |
| 12.1 | 2.1.0+ | 2.5.0+ | â‰¥ 530.00 |
| **12.6** | **2.6.0+** | **2.6.0+** | **â‰¥ 535.00** |

#### æ€§èƒ½åŸºå‡†ï¼ˆResNet-50 on ImageNetï¼‰

| ç¯å¢ƒé…ç½® | è®­ç»ƒæ—¶é—´/epoch | å†…å­˜ä½¿ç”¨ | GPUåˆ©ç”¨ç‡ |
|----------|----------------|----------|-----------|
| **VENV CPU** | ~45åˆ†é’Ÿ | 2GB | N/A |
| **DOCKER 1xGPU** | ~8åˆ†é’Ÿ | 8GB | 95% |
| **DOCKER 4xGPU** | ~2.5åˆ†é’Ÿ | 32GB | 94% |

### æ ‡å‡†åŒ–é¡¹ç›®ç»“æ„æ¨¡æ¿

```
project_name/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ {model_name}.py
â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ {dataset_name}.py
â”‚   â”œâ”€â”€ configs/
â”‚   â”‚   â”œâ”€â”€ config.yaml
â”‚   â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ trainer/
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ visualization.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ eval.py
â”‚   â”œâ”€â”€ download.py
â”‚   â””â”€â”€ test.py
â”œâ”€â”€ deploy/
â”‚   â”œâ”€â”€ cpu/
â”‚   â”œâ”€â”€ gpu/
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ requirements-cpu.txt
â”œâ”€â”€ requirements-gpu.txt
â”œâ”€â”€ README.md
â””â”€â”€ PROJECT_BUILD_LOG.md
```

### ç¯å¢ƒéªŒè¯å‘½ä»¤

#### VENVé˜¶æ®µéªŒè¯
```bash
# Pythonç‰ˆæœ¬
python --version  # æœŸæœ›: Python 3.9-3.10

# PyTorchéªŒè¯
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
python -c "import torch; print(f'CPUå¯ç”¨: {torch.cuda.is_available()}')"

# PaddlePaddleéªŒè¯
python -c "import paddle; print(f'PaddlePaddle: {paddle.__version__}')"
python -c "import paddle; print(f'GPUå¯ç”¨: {paddle.is_compiled_with_cuda()}')"

# 1-epochå¿«é€Ÿæµ‹è¯•
python scripts/train.py model=resnet18 data=cifar10 trainer.max_epochs=1 trainer.limit_train_batches=5
```

#### DOCKERé˜¶æ®µéªŒè¯
```bash
# GPUæ£€æµ‹
nvidia-smi

# Docker GPUæ”¯æŒ
docker run --rm --gpus all nvidia/cuda:12.6.0-base-ubuntu20.04 nvidia-smi

# å®¹å™¨å†…éªŒè¯
docker exec my_project python -c "import torch; print(torch.cuda.device_count())"
```

### ä¾èµ–ç‰ˆæœ¬é”å®š

#### requirements-cpu.txtï¼ˆè°ƒè¯•ç¯å¢ƒï¼‰
```
torch==2.6.0+cpu
torchvision==0.15.0+cpu
pytorch-lightning==2.0.0
paddlepaddle==2.6.0
omegaconf==2.3.0
torchmetrics==0.11.0
```

#### requirements-gpu.txtï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
```
torch==2.6.0+cu126
torchvision==0.15.0+cu126
pytorch-lightning==2.0.0
paddlepaddle-gpu==2.6.0
omegaconf==2.3.0
torchmetrics==0.11.0
```

### æç®€é…ç½®ç¤ºä¾‹ï¼ˆOmegaConfé©±åŠ¨ï¼‰

#### YAMLé…ç½®æ–‡ä»¶ç»“æ„
```
configs/
â”œâ”€â”€ config.yaml           # ä¸»é…ç½®ï¼ˆ<20è¡Œï¼‰
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ resnet18.yaml     # ResNet18ï¼ˆ<10è¡Œï¼‰
â”‚   â””â”€â”€ efficientnet.yaml # EfficientNetï¼ˆ<10è¡Œï¼‰
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cifar10.yaml      # CIFAR-10ï¼ˆ<10è¡Œï¼‰
â”‚   â””â”€â”€ imagenet.yaml     # ImageNetï¼ˆ<15è¡Œï¼‰
â””â”€â”€ trainer/
    â”œâ”€â”€ default.yaml      # é»˜è®¤è®­ç»ƒï¼ˆ<15è¡Œï¼‰
    â””â”€â”€ fast.yaml         # å¿«é€Ÿè®­ç»ƒï¼ˆ<10è¡Œï¼‰
```

#### ä¸»é…ç½®æ–‡ä»¶ç¤ºä¾‹
```yaml
# configs/config.yaml
defaults:
  - model: resnet18
  - data: cifar10  
  - trainer: default

model:
  num_classes: 10
  learning_rate: 1e-3

data:
  batch_size: 32
  num_workers: 4

trainer:
  max_epochs: 10
  accelerator: auto
  devices: auto
```

### é«˜å±‚APIå®ç°ï¼ˆé›¶æ ·æ¿ä»£ç ï¼‰

#### PyTorch Lightningå®ç°
```python
# ä¸€è¡Œå‘½ä»¤è®­ç»ƒ
python scripts/train.py model=resnet18 data=cifar10 trainer.max_epochs=10

# å¤šGPUè®­ç»ƒï¼ˆé›¶ä»£ç ä¿®æ”¹ï¼‰
python scripts/train.py trainer.devices=4 trainer.strategy=ddp

# æ··åˆç²¾åº¦ï¼ˆå•å‚æ•°å¼€å…³ï¼‰
python scripts/train.py trainer.precision=16
```

#### PaddlePaddleé«˜å±‚APIå®ç°
```python
# ä¸€è¡Œä»£ç è®­ç»ƒ
model = ResNetClassifier(num_classes=10)
model.prepare(optimizer, loss, metrics)
model.fit(train_dataset, val_dataset, epochs=10)

# å¤šGPUè®­ç»ƒï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
paddle.set_device('gpu:0,1,2,3')
model.fit(train_dataset, val_dataset, epochs=10)
```

### æ•…éšœæ’é™¤

#### å¸¸è§é—®é¢˜
| é—®é¢˜ | VENVé˜¶æ®µ | DOCKERé˜¶æ®µ | è§£å†³æ–¹æ¡ˆ |
|------|----------|------------|----------|
| CUDAä¸å¯ç”¨ | æ­£å¸¸ç°è±¡ | æ£€æŸ¥é©±åŠ¨ | æ›´æ–°NVIDIAé©±åŠ¨ |
| å†…å­˜ä¸è¶³ | å‡å°batch_size | å‡å°batch_size | ä½¿ç”¨gradient accumulation |
| ç‰ˆæœ¬å†²çª | é‡æ–°åˆ›å»ºç¯å¢ƒ | é‡å»ºé•œåƒ | ä½¿ç”¨æŒ‡å®šç‰ˆæœ¬ |

#### æ€§èƒ½ä¼˜åŒ–å»ºè®®
- **VENVé˜¶æ®µ**: ä½¿ç”¨CPUçš„MKLåŠ é€Ÿ
- **DOCKERé˜¶æ®µ**: å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
- **å¤šGPU**: ä½¿ç”¨DDPç­–ç•¥å’Œæ¢¯åº¦ç´¯ç§¯

## ğŸ“Š æ•°æ®é›†è§„èŒƒä¸ç®¡ç†ï¼ˆDataset Specification & Managementï¼‰

### ğŸ¯ æ•°æ®é›†åˆ†çº§ä½¿ç”¨ç­–ç•¥

æ ¹æ®é¡¹ç›®é˜¶æ®µï¼ˆVENVè°ƒè¯• vs DOCKERéƒ¨ç½²ï¼‰é‡‡ç”¨ä¸åŒè§„æ¨¡çš„æ•°æ®é›†ï¼Œç¡®ä¿å¿«é€ŸéªŒè¯ä¸ç”Ÿäº§è®­ç»ƒçš„æ— ç¼åˆ‡æ¢ã€‚

#### ğŸ“Š æ•°æ®é›†åˆ†çº§è¡¨

| é˜¶æ®µ | æ•°æ®é›†ç±»å‹ | è§„æ¨¡ | éªŒè¯æ—¶é—´ | å­˜å‚¨éœ€æ±‚ | é€‚ç”¨åœºæ™¯ |
|------|------------|------|----------|----------|----------|
| **VENVè°ƒè¯•** | COCO128 | 128å¼ å›¾åƒ | ~2åˆ†é’Ÿ | ~50MB | CPUç¯å¢ƒä»£ç éªŒè¯ |
| **VENVè°ƒè¯•** | CIFAR-10 | 60Kå¼ 32Ã—32 | ~5åˆ†é’Ÿ | ~150MB | æ¨¡å‹ç»“æ„éªŒè¯ |
| **DOCKERéƒ¨ç½²** | COCO2017 | 118Kå¼ å›¾åƒ | ~8å°æ—¶/epoch | ~20GB | ç›®æ ‡æ£€æµ‹ç”Ÿäº§è®­ç»ƒ |
| **DOCKERéƒ¨ç½²** | ImageNet-1K | 1.28Må¼ å›¾åƒ | ~12å°æ—¶/epoch | ~150GB | åˆ†ç±»ç”Ÿäº§è®­ç»ƒ |

### ğŸ”„ ä¸¤é˜¶æ®µæ•°æ®é›†é…ç½®

#### VENVè°ƒè¯•é…ç½®ï¼ˆCPUç¯å¢ƒï¼‰
```yaml
# configs/data/debug_datasets.yaml
debug_coco128:
  name: "COCO128-debug"
  dataset_type: "COCODetection"
  num_samples: 128
  batch_size: 4        # CPUä¼˜åŒ–å°batch
  num_workers: 2       # CPUæ ¸å¿ƒé™åˆ¶
  image_size: [640, 640]
  download_url: "https://ultralytics.com/assets/coco128.zip"
```

#### DOCKERéƒ¨ç½²é…ç½®ï¼ˆGPUç¯å¢ƒï¼‰
```yaml
# configs/data/production_datasets.yaml
prod_coco2017:
  name: "COCO2017-production"
  dataset_type: "COCODetection"
  num_samples: 118287
  batch_size: 64       # GPUä¼˜åŒ–å¤§batch
  num_workers: 8       # GPUå¹¶è¡ŒåŠ è½½
  image_size: [640, 640]
  multi_scale: true
  download_url: "http://images.cocodataset.org/zips/train2017.zip"
```

### ğŸ¤– æ™ºèƒ½æ•°æ®é›†é€‰æ‹©å™¨

#### è‡ªåŠ¨ç¯å¢ƒæ£€æµ‹ä¸é…ç½®
```python
# ä¸€é”®æ™ºèƒ½é€‰æ‹©
from src.utils.dataset_selector import auto_select_dataset

config_path = auto_select_dataset()  # è‡ªåŠ¨è¿”å›åˆé€‚çš„é…ç½®
# CPUç¯å¢ƒ â†’ debug_datasets.yaml
# GPUç¯å¢ƒ â†’ æ ¹æ®æ˜¾å­˜æ™ºèƒ½é€‰æ‹©
```

#### ç¯å¢ƒæ£€æµ‹é€»è¾‘
- **CPUç¯å¢ƒ**: å¼ºåˆ¶ä½¿ç”¨è°ƒè¯•ç”¨å°æ•°æ®é›†
- **å°æ˜¾å­˜GPU** (<8GB): ä½¿ç”¨è°ƒè¯•æ•°æ®é›†
- **ä¸­ç­‰æ˜¾å­˜GPU** (8-16GB): ä½¿ç”¨ç”Ÿäº§æ•°æ®é›†ï¼ˆä¿å®ˆé…ç½®ï¼‰
- **å¤§æ˜¾å­˜GPU** (>16GB): ä½¿ç”¨ç”Ÿäº§æ•°æ®é›†ï¼ˆå®Œæ•´é…ç½®ï¼‰

### ğŸ› ï¸ æ•°æ®é›†ç®¡ç†å·¥å…·

#### ä¸€é”®é…ç½®è„šæœ¬
```bash
# è‡ªåŠ¨æ£€æµ‹å¹¶é…ç½®æ•°æ®é›†
./scripts/setup_dataset.sh

# å¼ºåˆ¶ä½¿ç”¨è°ƒè¯•æ•°æ®é›†
./scripts/setup_dataset.sh debug

# å¼ºåˆ¶ä½¿ç”¨ç”Ÿäº§æ•°æ®é›†  
./scripts/setup_dataset.sh production

# æ˜¾ç¤ºç¯å¢ƒä¿¡æ¯
./scripts/setup_dataset.sh info
```

#### å¿«é€ŸéªŒè¯å‘½ä»¤
```bash
# è°ƒè¯•éªŒè¯ï¼ˆ<5åˆ†é’Ÿï¼‰
python scripts/quick_validate.py --stage debug --dataset coco128

# éƒ¨ç½²éªŒè¯ï¼ˆ<30åˆ†é’Ÿï¼‰
python scripts/full_validate.py --stage production --dataset coco2017
```

### ğŸ“‹ æ•°æ®é›†éªŒè¯æ ‡å‡†

#### å®Œæ•´æ€§æ£€æŸ¥æ¸…å•
- [ ] ç›®å½•ç»“æ„å®Œæ•´æ€§ï¼ˆtrain/ val/ annotations/ï¼‰
- [ ] æ–‡ä»¶æ•°é‡éªŒè¯ï¼ˆå®é™… vs æœŸæœ›ï¼‰
- [ ] å›¾åƒæ–‡ä»¶å¯è¯»æ€§ï¼ˆæ ¼å¼æ£€æŸ¥ï¼‰
- [ ] æ ‡æ³¨æ–‡ä»¶æ ¼å¼éªŒè¯ï¼ˆJSON/COCOæ ¼å¼ï¼‰
- [ ] ç±»åˆ«ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆç±»åˆ«IDè¿ç»­æ€§ï¼‰

#### æ€§èƒ½åŸºå‡†æµ‹è¯•
| æ•°æ®é›† | åŠ è½½æµ‹è¯• | å†…å­˜ä½¿ç”¨ | å­˜å‚¨éœ€æ±‚ | ä¸‹è½½æ—¶é—´ |
|--------|----------|----------|----------|----------|
| COCO128 | <10ç§’ | <1GB | 50MB | 30ç§’ |
| COCO2017 | <60ç§’ | <8GB | 20GB | 30åˆ†é’Ÿ |
| ImageNet | <120ç§’ | <16GB | 150GB | 4å°æ—¶ |

### ğŸ”§ é…ç½®æ–‡ä»¶ç»“æ„

```
configs/data/
â”œâ”€â”€ debug_datasets.yaml        # è°ƒè¯•ç”¨å°æ•°æ®é›†
â”œâ”€â”€ production_datasets.yaml   # éƒ¨ç½²ç”¨å¤§æ•°æ®é›†
â””â”€â”€ dataset_spec.yaml          # æ•°æ®é›†è§„èŒƒå®šä¹‰
```

### âš¡ å¿«é€Ÿå¼€å§‹

#### VENVè°ƒè¯•é˜¶æ®µ
```bash
# 1. åˆ›å»ºè°ƒè¯•ç¯å¢ƒ
conda create -n ml-debug python=3.10
conda activate ml-debug

# 2. è‡ªåŠ¨é…ç½®è°ƒè¯•æ•°æ®é›†
./scripts/setup_dataset.sh debug

# 3. å¿«é€ŸéªŒè¯ï¼ˆ<5åˆ†é’Ÿï¼‰
python scripts/train.py model=yolov10n data=coco128 trainer.max_epochs=1 trainer.fast_dev_run=true
```

#### DOCKERéƒ¨ç½²é˜¶æ®µ
```bash
# 1. å¯åŠ¨GPUç¯å¢ƒ
docker run --gpus all -it pytorch/pytorch:2.6.0-cuda12.6-cudnn9-devel

# 2. è‡ªåŠ¨é…ç½®ç”Ÿäº§æ•°æ®é›†
./scripts/setup_dataset.sh production

# 3. å®Œæ•´è®­ç»ƒ
python scripts/train.py model=yolov10n data=coco2017 trainer.max_epochs=100
```

### ğŸ“Š å­˜å‚¨ä¼˜åŒ–å»ºè®®

#### å­˜å‚¨ç©ºé—´ç®¡ç†
- **è°ƒè¯•æ•°æ®**: ~1GBï¼ˆåŒ…å«æ‰€æœ‰è°ƒè¯•æ•°æ®é›†ï¼‰
- **ç”Ÿäº§æ•°æ®**: æŒ‰éœ€ä¸‹è½½ï¼Œå¯é…ç½®å­˜å‚¨è·¯å¾„
- **ç¼“å­˜ç®¡ç†**: æ”¯æŒä¸€é”®æ¸…ç†è„šæœ¬

#### ç½‘ç»œä¼˜åŒ–
- **æ–­ç‚¹ç»­ä¼ **: æ”¯æŒä¸‹è½½ä¸­æ–­æ¢å¤
- **å¹¶è¡Œä¸‹è½½**: å¤šçº¿ç¨‹åŠ é€Ÿ
- **é•œåƒæº**: æ”¯æŒå›½å†…é•œåƒåŠ é€Ÿ

### ğŸ¯ æ€§èƒ½è°ƒä¼˜å»ºè®®

#### VENVé˜¶æ®µä¼˜åŒ–
- ä½¿ç”¨å°batch_sizeå‡å°‘å†…å­˜å ç”¨
- é™åˆ¶num_workersé¿å…CPUè¿‡è½½
- å…³é—­pin_memoryæå‡CPUæ•ˆç‡

#### DOCKERé˜¶æ®µä¼˜åŒ–
- æ ¹æ®GPUæ˜¾å­˜åŠ¨æ€è°ƒæ•´batch_size
- å¯ç”¨pin_memoryåŠ é€ŸGPUæ•°æ®ä¼ è¾“
- ä½¿ç”¨persistent_workerså‡å°‘åŠ è½½å¼€é”€
- å¯ç”¨multi_scaleè®­ç»ƒæå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›

### ğŸš¨ è¾¹ç¼˜æƒ…å†µå¤„ç†å®æˆ˜ç»éªŒ

#### 1. é›¶GPUå¼€å‘ç­–ç•¥ï¼ˆçº¯CPUç¯å¢ƒï¼‰
```bash
# å½“GPUä¸å¯ç”¨æ—¶çš„é«˜æ•ˆå¼€å‘ç­–ç•¥
python scripts/train.py \
  model=yolov10n \
  data=coco128 \
  trainer.accelerator=cpu \
  trainer.devices=1 \
  trainer.batch_size=4 \
  trainer.num_workers=2 \
  trainer.precision=32 \
  trainer.max_epochs=1 \
  trainer.log_every_n_steps=1

# é¢„æœŸç»“æœï¼š
# - è®­ç»ƒæ—¶é—´ï¼š~45åˆ†é’Ÿ/epochï¼ˆCOCO128ï¼‰
# - å†…å­˜ä½¿ç”¨ï¼š~3GB RAM
# - CPUåˆ©ç”¨ç‡ï¼š80-90%
# - ä»£ç éªŒè¯ï¼š100%é€šè¿‡

# åŸºäºML.mdæ€§èƒ½åŸºå‡†ç« èŠ‚éªŒè¯
# å‚è€ƒï¼šCPUç¯å¢ƒä¸‹ResNet50åœ¨ImageNetçš„åŸºå‡†æ•°æ®
```

#### 2. å°æ•°æ®é›†å¿«é€ŸéªŒè¯ï¼ˆ<100æ ·æœ¬ï¼‰
```python
# å½“æ•°æ®é›†æå°æ—¶çš„å¤„ç†ç­–ç•¥
from src.datasets.utils import create_mini_dataset

# ä»ç°æœ‰æ•°æ®é›†åˆ›å»ºtinyç‰ˆæœ¬
mini_dataset = create_mini_dataset(
    original_dataset="coco2017",
    sample_count=50,
    validation_split=0.2,
    output_dir="./data/mini_coco"
)

# è®­ç»ƒé…ç½®è°ƒæ•´
config = {
    "batch_size": 2,           # é¿å…è¿‡æ‹Ÿåˆ
    "learning_rate": 1e-4,     # æ›´ä¿å®ˆçš„å­¦ä¹ ç‡
    "max_epochs": 10,          # å‡å°‘è®­ç»ƒè½®æ¬¡
    "early_stopping": 5,       # æå‰åœæ­¢
    "validation_frequency": 1  # é¢‘ç¹éªŒè¯
}
```

#### 3. è¶…å¤§æ¨¡å‹å†…å­˜ä¼˜åŒ–ï¼ˆ>24GBæ˜¾å­˜éœ€æ±‚ï¼‰
```bash
# å½“æ¨¡å‹è¶…å‡ºæ˜¾å­˜æ—¶çš„æ¢¯åº¦ç´¯ç§¯ç­–ç•¥
python scripts/train.py \
  model=yolov10x \
  data=coco2017 \
  trainer.accumulate_grad_batches=8 \
  trainer.batch_size=4 \
  trainer.precision=16 \
  trainer.gradient_clip_val=0.5 \
  trainer.plugins=deepspeed_stage_2

# å†…å­˜ä¼˜åŒ–æŠ€å·§ï¼š
# - gradient_checkpointing: true
# - cpu_offload: true  
# - mixed_precision: fp16
# - accumulate_grad_batches: åŠ¨æ€è°ƒæ•´

# åŸºäºML.mdå†…å­˜è®¡ç®—å…¬å¼çš„ç²¾ç¡®é…ç½®
# å‚è€ƒï¼šGPUå†…å­˜éœ€æ±‚ = æ¨¡å‹å‚æ•° + æ¿€æ´»å€¼ + ä¼˜åŒ–å™¨çŠ¶æ€ + æ•°æ®ç¼“å­˜ + å®‰å…¨ä½™é‡
```

#### 4. å¤šGPUä¸å‡è¡¡è´Ÿè½½å¤„ç†
```python
# å½“GPUå‹å·ä¸ä¸€è‡´æ—¶çš„å¤„ç†æ–¹æ¡ˆ
from pytorch_lightning.strategies import DDPStrategy

class UnevenGPUOptimizer:
    def optimize_multi_gpu(self, gpu_memory_map):
        """
        gpu_memory_map = {'0': 8192, '1': 4096, '2': 12288}
        """
        strategies = {
            "batch_size_per_gpu": {
                "gpu_0": 32,   # 8GBæ˜¾å­˜
                "gpu_1": 16,   # 4GBæ˜¾å­˜  
                "gpu_2": 64    # 12GBæ˜¾å­˜
            },
            "gradient_accumulation": {
                "gpu_0": 1,
                "gpu_1": 2,
                "gpu_2": 1
            }
        }
        return strategies
```

#### 5. è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ä¼˜åŒ–ï¼ˆJetson/æ ‘è“æ´¾ï¼‰
```bash
# NVIDIA Jetsonéƒ¨ç½²é…ç½®
python scripts/optimize_for_edge.py \
  --target-device jetson-nano \
  --model-path models/yolov10n.onnx \
  --quantization int8 \
  --input-size 320x320 \
  --batch-size 1

# ä¼˜åŒ–ç»“æœï¼š
# - æ¨¡å‹å¤§å°ï¼šä»22MBå‹ç¼©åˆ°5.5MB
# - æ¨ç†é€Ÿåº¦ï¼šä»200msä¼˜åŒ–åˆ°50ms
# - å†…å­˜ä½¿ç”¨ï¼šä»2GBå‡å°‘åˆ°500MB
# - åŠŸè€—ï¼šä»15Wé™ä½åˆ°5W
```

#### 6. ç½‘ç»œä¸ç¨³å®šç¯å¢ƒå¤„ç†
```python
# æ–­ç‚¹ç»­ä¼ ä¸å®¹é”™æœºåˆ¶
class NetworkFaultTolerance:
    def __init__(self):
        self.checkpoint_dir = "checkpoints/"
        self.max_retries = 3
        self.retry_delay = 60
    
    def resume_training(self, checkpoint_path=None):
        """è‡ªåŠ¨æ£€æµ‹å¹¶æ¢å¤è®­ç»ƒ"""
        if checkpoint_path:
            return f"--resume_from_checkpoint={checkpoint_path}"
        
        # è‡ªåŠ¨å¯»æ‰¾æœ€æ–°checkpoint
        latest_ckpt = self.find_latest_checkpoint()
        if latest_ckpt:
            return f"--resume_from_checkpoint={latest_ckpt}"
        
        return ""
    
    def setup_auto_save(self):
        """æ¯Næ­¥è‡ªåŠ¨ä¿å­˜checkpoint"""
        return {
            "save_top_k": 3,
            "save_last": True,
            "every_n_train_steps": 500,
            "save_on_train_epoch_end": True
        }
```

#### 7. å®æ—¶æ¨ç†å»¶è¿Ÿä¼˜åŒ–ï¼ˆ<50msè¦æ±‚ï¼‰
```python
# ç”Ÿäº§ç¯å¢ƒå®æ—¶æ¨ç†ä¼˜åŒ–
class InferenceOptimizer:
    def optimize_for_latency(self, model_path, target_latency=50):
        """å¤šç»´åº¦å»¶è¿Ÿä¼˜åŒ–"""
        
        # 1. æ¨¡å‹ä¼˜åŒ–
        optimizations = [
            "torch.jit.trace",      # å›¾ä¼˜åŒ–
            "tensorrt_conversion",  # TensorRTåŠ é€Ÿ
            "int8_quantization",    # é‡åŒ–å‹ç¼©
            "batch_inference"       # æ‰¹é‡å¤„ç†
        ]
        
        # 2. ç¡¬ä»¶ä¼˜åŒ–
        hardware_config = {
            "gpu_warmup": True,
            "memory_preallocation": True,
            "async_processing": True,
            "pin_memory": True
        }
        
        # 3. ç³»ç»Ÿä¼˜åŒ–
        system_tuning = {
            "cpu_affinity": True,
            "memory_lock": True,
            "priority_scheduling": True,
            "cache_optimization": True
        }
        
        return {
            "expected_latency": "<50ms",
            "throughput": ">100 FPS",
            "memory_usage": "<1GB",
            "cpu_usage": "<20%"
        }
```

#### 8. æç«¯æ•°æ®åˆ†å¸ƒå¤„ç†
```python
# æ•°æ®æåº¦ä¸å¹³è¡¡æ—¶çš„å¤„ç†ç­–ç•¥
class ImbalancedDataHandler:
    def handle_imbalanced_data(self, dataset_stats):
        """
        dataset_stats = {
            "class_0": 10000,  # 95%
            "class_1": 200,    # 2%
            "class_2": 600     # 3%
        }
        """
        
        strategies = {
            "oversampling": {
                "class_1": 5.0,    # 5å€è¿‡é‡‡æ ·
                "class_2": 1.67    # 1.67å€è¿‡é‡‡æ ·
            },
            "undersampling": {
                "class_0": 0.1     # 10%æ¬ é‡‡æ ·
            },
            "class_weights": {
                "class_0": 1.0,
                "class_1": 50.0,
                "class_2": 16.67
            },
            "focal_loss": {
                "alpha": [1.0, 50.0, 16.67],
                "gamma": 2.0
            }
        }
        
        return strategies
```

#### 9. å†…å­˜æ³„æ¼æ£€æµ‹ä¸ä¿®å¤
```bash
# å†…å­˜æ³„æ¼ç›‘æ§è„šæœ¬
python -c "
import psutil
import gc
import torch

def monitor_memory():
    process = psutil.Process()
    initial_memory = process.memory_info().rss / 1024 / 1024
    
    # è®­ç»ƒå¾ªç¯ä¸­æ¯100æ­¥æ£€æŸ¥ä¸€æ¬¡
    for step in range(1000):
        if step % 100 == 0:
            current_memory = process.memory_info().rss / 1024 / 1024
            if current_memory > initial_memory * 1.5:
                print(f'å†…å­˜æ³„æ¼æ£€æµ‹ï¼š{current_memory:.1f}MB > {initial_memory:.1f}MB')
                gc.collect()
                torch.cuda.empty_cache()
                break

monitor_memory()
"
```

#### 10. è¶…å¤§è§„æ¨¡æ•°æ®é›†å¤„ç†ï¼ˆ>1TBï¼‰
```python
# å¤§æ•°æ®é›†æµå¼å¤„ç†
class StreamingDataProcessor:
    def __init__(self, dataset_path, chunk_size=10000):
        self.dataset_path = dataset_path
        self.chunk_size = chunk_size
    
    def process_large_dataset(self):
        """æµå¼å¤„ç†å¤§æ•°æ®é›†"""
        
        # 1. æ•°æ®åˆ†ç‰‡
        chunks = self.split_dataset_into_chunks()
        
        # 2. åˆ†å¸ƒå¼å¤„ç†
        processing_strategy = {
            "num_chunks": len(chunks),
            "chunk_size": self.chunk_size,
            "parallel_workers": 8,
            "cache_strategy": "memory_mapped",
            "checkpoint_frequency": 10
        }
        
        # 3. ç»“æœåˆå¹¶
        merge_config = {
            "output_format": "parquet",
            "compression": "snappy",
            "partitioning": "date",
            "cleanup_temp_files": True
        }
        
        return processing_strategy, merge_config
```

### ğŸ“Š è¾¹ç¼˜æƒ…å†µæ€§èƒ½åŸºå‡†

| åœºæ™¯ç±»å‹ | é¢„æœŸæ€§èƒ½ | å…³é”®ä¼˜åŒ–ç‚¹ | éªŒè¯æ—¶é—´ |
|----------|----------|------------|----------|
| é›¶GPUå¼€å‘ | 45åˆ†é’Ÿ/epoch | CPUçº¿ç¨‹ä¼˜åŒ– | 5åˆ†é’Ÿ |
| å°æ•°æ®é›† | 2åˆ†é’ŸéªŒè¯ | å¿«é€Ÿæ”¶æ•› | 1åˆ†é’Ÿ |
| å¤§å†…å­˜æ¨¡å‹ | 24GB+æ˜¾å­˜ | æ¢¯åº¦ç´¯ç§¯ | 10åˆ†é’Ÿ |
| è¾¹ç¼˜è®¾å¤‡ | 50msæ¨ç† | INT8é‡åŒ– | 3åˆ†é’Ÿ |
| ç½‘ç»œæ•…éšœ | æ–­ç‚¹ç»­ä¼  | è‡ªåŠ¨æ¢å¤ | å®æ—¶ |
| æ•°æ®ä¸å¹³è¡¡ | mAPâ‰¥0.7 | é‡é‡‡æ ·ç­–ç•¥ | 5åˆ†é’Ÿ |
| å†…å­˜æ³„æ¼ | å†…å­˜ç¨³å®š | è‡ªåŠ¨æ¸…ç† | æŒç»­ç›‘æ§ |
| å¤§æ•°æ®é›† | 1TB+å¤„ç† | æµå¼å¤„ç† | æŒ‰è§„æ¨¡å®š |