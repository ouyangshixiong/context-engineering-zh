"""
æ™ºèƒ½æ•°æ®é›†é€‰æ‹©å™¨
æ ¹æ®è¿è¡Œç¯å¢ƒè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„è°ƒè¯•æˆ–ç”Ÿäº§æ•°æ®é›†
"""

import os
import torch
import yaml
from pathlib import Path
from typing import Dict, Any, Optional
import logging

logger = logging.getLogger(__name__)

class DatasetSelector:
    """æ™ºèƒ½æ•°æ®é›†é€‰æ‹©å™¨ï¼Œæ ¹æ®ç¯å¢ƒè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ•°æ®é›†"""
    
    def __init__(self, config_dir: str = "configs/data"):
        self.config_dir = Path(config_dir)
        self.debug_config = self.config_dir / "debug_datasets.yaml"
        self.prod_config = self.config_dir / "production_datasets.yaml"
        
    def get_environment_info(self) -> Dict[str, Any]:
        """è·å–å½“å‰è¿è¡Œç¯å¢ƒä¿¡æ¯"""
        info = {
            "cuda_available": torch.cuda.is_available(),
            "device_count": 0,
            "gpu_memory": {},
            "cpu_count": os.cpu_count(),
            "memory_available": None,
        }
        
        if info["cuda_available"]:
            info["device_count"] = torch.cuda.device_count()
            for i in range(info["device_count"]):
                props = torch.cuda.get_device_properties(i)
                info["gpu_memory"][f"gpu_{i}"] = {
                    "name": props.name,
                    "total_memory_gb": props.total_memory / 1024**3,
                    "memory_gb": round(props.total_memory / 1024**3, 1)
                }
        
        # è·å–å¯ç”¨å†…å­˜ï¼ˆè¿‘ä¼¼ï¼‰
        try:
            import psutil
            memory = psutil.virtual_memory()
            info["memory_available"] = memory.available / 1024**3
        except ImportError:
            info["memory_available"] = 8.0  # é»˜è®¤å€¼
            
        return info
    
    def select_dataset_config(self) -> str:
        """æ ¹æ®ç¯å¢ƒä¿¡æ¯é€‰æ‹©åˆé€‚çš„æ•°æ®é›†é…ç½®"""
        env_info = self.get_environment_info()
        
        logger.info(f"ç¯å¢ƒä¿¡æ¯: {env_info}")
        
        # å†³ç­–é€»è¾‘
        if not env_info["cuda_available"]:
            # CPUç¯å¢ƒï¼šå¼ºåˆ¶ä½¿ç”¨è°ƒè¯•æ•°æ®é›†
            logger.info("CPUç¯å¢ƒæ£€æµ‹ï¼Œä½¿ç”¨è°ƒè¯•æ•°æ®é›†")
            return str(self.debug_config)
        
        # GPUç¯å¢ƒï¼šæ ¹æ®æ˜¾å­˜å¤§å°é€‰æ‹©
        gpu_memory = list(env_info["gpu_memory"].values())[0]["memory_gb"]
        
        if gpu_memory < 8:
            # å°æ˜¾å­˜ï¼šä½¿ç”¨è°ƒè¯•æ•°æ®é›†
            logger.info(f"å°æ˜¾å­˜GPU({gpu_memory}GB)ï¼Œä½¿ç”¨è°ƒè¯•æ•°æ®é›†")
            return str(self.debug_config)
        elif gpu_memory < 16:
            # ä¸­ç­‰æ˜¾å­˜ï¼šä½¿ç”¨ç”Ÿäº§æ•°æ®é›†ï¼Œä½†é™åˆ¶batch size
            logger.info(f"ä¸­ç­‰æ˜¾å­˜GPU({gpu_memory}GB)ï¼Œä½¿ç”¨ç”Ÿäº§æ•°æ®é›†(ä¿å®ˆé…ç½®)")
            return str(self.prod_config)
        else:
            # å¤§æ˜¾å­˜ï¼šä½¿ç”¨ç”Ÿäº§æ•°æ®é›†ï¼Œå®Œæ•´é…ç½®
            logger.info(f"å¤§æ˜¾å­˜GPU({gpu_memory}GB)ï¼Œä½¿ç”¨ç”Ÿäº§æ•°æ®é›†(å®Œæ•´é…ç½®)")
            return str(self.prod_config)
    
    def get_recommended_batch_size(self, dataset_name: str) -> int:
        """æ ¹æ®GPUå†…å­˜æ¨èåˆé€‚çš„batch size"""
        env_info = self.get_environment_info()
        
        if not env_info["cuda_available"]:
            return 4  # CPUç¯å¢ƒå°batch
        
        gpu_memory = list(env_info["gpu_memory"].values())[0]["memory_gb"]
        
        # åŸºäºæ•°æ®é›†å’Œæ˜¾å­˜çš„batch sizeæ˜ å°„
        batch_size_map = {
            "coco128": {8: 16, 16: 32, 24: 64},
            "coco2017": {8: 16, 16: 32, 24: 64, 48: 128},
            "imagenet": {8: 64, 16: 128, 24: 256, 48: 512},
            "cifar10": {8: 128, 16: 256, 24: 512},
            "tiny_imagenet": {8: 64, 16: 128, 24: 256},
            "openimages": {8: 8, 16: 16, 24: 32, 48: 64}
        }
        
        if dataset_name in batch_size_map:
            # æ‰¾åˆ°æœ€é€‚åˆçš„æ˜¾å­˜æ¡£ä½
            memory_keys = sorted(batch_size_map[dataset_name].keys())
            for mem_key in memory_keys:
                if gpu_memory >= mem_key:
                    return batch_size_map[dataset_name][mem_key]
        
        # é»˜è®¤ä¿å®ˆå€¼
        return min(16, int(gpu_memory * 2))
    
    def load_dataset_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½æ•°æ®é›†é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            return config
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return {}
    
    def get_dataset_info(self, dataset_name: str, stage: str = "auto") -> Dict[str, Any]:
        """è·å–æŒ‡å®šæ•°æ®é›†çš„è¯¦ç»†ä¿¡æ¯"""
        if stage == "auto":
            config_path = self.select_dataset_config()
        elif stage == "debug":
            config_path = str(self.debug_config)
        elif stage == "production":
            config_path = str(self.prod_config)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„stage: {stage}")
        
        config = self.load_dataset_config(config_path)
        
        # æ ¹æ®é…ç½®ç±»å‹æå–å¯¹åº”æ•°æ®é›†ä¿¡æ¯
        if "debug_datasets" in config and dataset_name in config["debug_datasets"]:
            dataset_info = config["debug_datasets"][dataset_name]
        elif "production_datasets" in config and dataset_name in config["production_datasets"]:
            dataset_info = config["production_datasets"][dataset_name]
        else:
            raise ValueError(f"æ•°æ®é›† {dataset_name} æœªåœ¨é…ç½®ä¸­æ‰¾åˆ°")
        
        # æ·»åŠ æ¨èçš„batch size
        dataset_info["recommended_batch_size"] = self.get_recommended_batch_size(dataset_name)
        dataset_info["config_path"] = config_path
        dataset_info["stage"] = "debug" if "debug" in config_path else "production"
        
        return dataset_info
    
    def print_environment_summary(self):
        """æ‰“å°ç¯å¢ƒæ‘˜è¦"""
        env_info = self.get_environment_info()
        
        print("=" * 50)
        print("ğŸ–¥ï¸  ç¯å¢ƒä¿¡æ¯æ‘˜è¦")
        print("=" * 50)
        
        print(f"CUDAå¯ç”¨: {env_info['cuda_available']}")
        print(f"CPUæ ¸å¿ƒæ•°: {env_info['cpu_count']}")
        print(f"å¯ç”¨å†…å­˜: {env_info['memory_available']:.1f}GB")
        
        if env_info['cuda_available']:
            print(f"GPUæ•°é‡: {env_info['device_count']}")
            for gpu_key, gpu_info in env_info['gpu_memory'].items():
                print(f"  {gpu_info['name']}: {gpu_info['memory_gb']}GB")
        
        selected_config = self.select_dataset_config()
        print(f"é€‰æ‹©çš„æ•°æ®é›†é…ç½®: {Path(selected_config).name}")
        print("=" * 50)

# å¿«æ·ä½¿ç”¨å‡½æ•°
def get_dataset_config(dataset_name: str = None, stage: str = "auto") -> Dict[str, Any]:
    """è·å–æ•°æ®é›†é…ç½®çš„å¿«æ·å‡½æ•°"""
    selector = DatasetSelector()
    
    if dataset_name is None:
        # è¿”å›é…ç½®è·¯å¾„
        return {"config_path": selector.select_dataset_config()}
    
    return selector.get_dataset_info(dataset_name, stage)

def auto_setup_dataset():
    """è‡ªåŠ¨è®¾ç½®æ•°æ®é›†"""
    selector = DatasetSelector()
    config_path = selector.select_dataset_config()
    
    print(f"è‡ªåŠ¨é€‰æ‹©çš„æ•°æ®é›†é…ç½®: {config_path}")
    selector.print_environment_summary()
    
    return config_path

if __name__ == "__main__":
    # å‘½ä»¤è¡Œä½¿ç”¨
    import argparse
    
    parser = argparse.ArgumentParser(description="æ™ºèƒ½æ•°æ®é›†é€‰æ‹©å™¨")
    parser.add_argument("--dataset", type=str, help="æ•°æ®é›†åç§°")
    parser.add_argument("--stage", type=str, choices=["auto", "debug", "production"], 
                       default="auto", help="é€‰æ‹©é˜¶æ®µ")
    parser.add_argument("--info", action="store_true", help="æ˜¾ç¤ºç¯å¢ƒä¿¡æ¯")
    
    args = parser.parse_args()
    
    selector = DatasetSelector()
    
    if args.info:
        selector.print_environment_summary()
    
    if args.dataset:
        info = selector.get_dataset_info(args.dataset, args.stage)
        print("\nğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        print(f"åç§°: {info['name']}")
        print(f"ç±»å‹: {info['dataset_type']}")
        print(f"æè¿°: {info['description']}")
        print(f"æ ·æœ¬æ•°: {info['num_samples']}")
        print(f"æ¨èbatch_size: {info['recommended_batch_size']}")
        print(f"é…ç½®è·¯å¾„: {info['config_path']}")
        print(f"é˜¶æ®µ: {info['stage']}")
    else:
        config_path = selector.select_dataset_config()
        print(f"\né€‰æ‹©çš„æ•°æ®é›†é…ç½®: {config_path}")