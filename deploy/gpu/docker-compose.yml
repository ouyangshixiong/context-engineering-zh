version: '3.8'

services:
  cnn-gpu:
    build:
      context: ../..
      dockerfile: deploy/gpu/Dockerfile
    container_name: cnn-tutorial-gpu
    ports:
      - "8888:8888"  # Jupyter Lab
      - "8000:8000"  # FastAPI/其他服务
    volumes:
      - ../..:/app
      - ./data:/app/data
    environment:
      - PYTHONPATH=/app
      - JUPYTER_ENABLE_LAB=yes
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0,1,2,3
    runtime: nvidia
    command: jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root
    healthcheck:
      test: ["CMD", "python", "-c", "import torch; import paddle; print('GPU ML libraries loaded')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

volumes:
  data:
    driver: local

networks:
  default:
    name: cnn-gpu-network